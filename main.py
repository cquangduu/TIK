"""
================================================================================
DAILY KOREAN â€” main.py (CONTENT AUTOMATION SYSTEM)
================================================================================
Architecture:
    Phase 1  â†’ Crawl News + Ra Ä‘á» thi TOPIK 54
    Phase 2  â†’ Viáº¿t vÄƒn máº«u + PhÃ¢n tÃ­ch tá»« vá»±ng & ngá»¯ phÃ¡p
    Phase 3  â†’ Multi-channel editor â†’ JSON cáº¥u trÃºc cho 4 video TikTok + Word doc
    Phase 4  â†’ Deep Dive Episode â†’ JSON cáº¥u trÃºc cho Video 5 (YouTube dÃ i)
    Assets   â†’ generate_tiktok_assets() â†’ 5 video vá»›i segment-based MP3
    Render   â†’ 5Ã— remotion render (5 CompositionID khÃ¡c nhau)
    Upload   â†’ Google Drive (Word + 5 Video + YouTube metadata)
================================================================================
CHANGES (v3.0 â€” DAILY KOREAN Edition):
    - Brand name: DAILY KOREAN (ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆ)
    - Azure TTS thay tháº¿ edge-tts (Cháº¥t lÆ°á»£ng cao hÆ¡n)
    - Phase 4: Ká»‹ch báº£n Deep Dive Episode (~5-10 phÃºt)
    - Video 5: YouTube Deep Dive vá»›i segment-based audio
    - YouTube Metadata: Auto-generate timestamps, title, hashtags
================================================================================
"""

import os
import json
import requests
import logging
import asyncio
import shutil
import random
import re
from bs4 import BeautifulSoup
from pydub import AudioSegment
import traceback
from datetime import datetime
import subprocess
import time
import platform

# ==================== AZURE TTS ====================
try:
    import azure.cognitiveservices.speech as speechsdk
    AZURE_TTS_AVAILABLE = True
except ImportError:
    AZURE_TTS_AVAILABLE = False
    logging.warning("âš ï¸ azure-cognitiveservices-speech not installed. Install with: pip install azure-cognitiveservices-speech")

# ==================== EDGE TTS FALLBACK ====================
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except ImportError:
    EDGE_TTS_AVAILABLE = False
    logging.warning("âš ï¸ edge-tts not installed. Install with: pip install edge-tts")

# Audio duration detection
try:
    from mutagen.mp3 import MP3
    MUTAGEN_AVAILABLE = True
except ImportError:
    MUTAGEN_AVAILABLE = False
    logging.warning("âš ï¸ mutagen not installed. Install with: pip install mutagen")

try:
    from docx import Document
    from docx.shared import Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
except ImportError:
    print("âš ï¸ Thiáº¿u thÆ° viá»‡n python-docx. HÃ£y cháº¡y: pip install python-docx")

# ==================== CONFIGURATION ====================
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# ==================== GOOGLE DRIVE UPLOAD ====================
import os.path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# ==================== YOUTUBE UPLOAD ====================
try:
    from youtube_uploader import (
        YouTubeUploader, 
        upload_tiktok_to_youtube, 
        upload_deep_dive_to_youtube
    )
    YOUTUBE_UPLOAD_AVAILABLE = True
except ImportError:
    YOUTUBE_UPLOAD_AVAILABLE = False
    logging.warning("âš ï¸ youtube_uploader module not found. YouTube upload disabled.")

# ==================== BLOG GENERATOR ====================
try:
    from blog_generator import generate_blog_from_data, BlogGenerator
    BLOG_GENERATOR_AVAILABLE = True
except ImportError:
    BLOG_GENERATOR_AVAILABLE = False
    logging.warning("âš ï¸ blog_generator module not found. Blog generation disabled.")

# ==================== PODCAST GENERATOR ====================
try:
    from podcast_generator import generate_podcast_from_data, PodcastGenerator
    PODCAST_GENERATOR_AVAILABLE = True
except ImportError:
    PODCAST_GENERATOR_AVAILABLE = False
    logging.warning("âš ï¸ podcast_generator module not found. Podcast generation disabled.")

# ==================== SOCIAL MEDIA PUBLISHER ====================
try:
    from social_publisher import publish_to_social_media, SocialMediaPublisher
    SOCIAL_PUBLISHER_AVAILABLE = True
except ImportError:
    SOCIAL_PUBLISHER_AVAILABLE = False
    logging.warning("âš ï¸ social_publisher module not found. Social media publishing disabled.")

# ==================== GITHUB DEPLOYER ====================
try:
    from github_deployer import deploy_blog_to_github, GitHubDeployer
    GITHUB_DEPLOYER_AVAILABLE = True
except ImportError:
    GITHUB_DEPLOYER_AVAILABLE = False
    logging.warning("âš ï¸ github_deployer module not found. GitHub deployment disabled.")

# ==================== MONETIZATION ====================
try:
    from monetization import MonetizationManager
    MONETIZATION_AVAILABLE = True
except ImportError:
    MONETIZATION_AVAILABLE = False
    logging.warning("âš ï¸ monetization module not found. Monetization features disabled.")

# ==================== TELEGRAM BOT ====================
try:
    from telegram_bot import send_daily_push
    TELEGRAM_BOT_AVAILABLE = True
except ImportError:
    TELEGRAM_BOT_AVAILABLE = False
    logging.warning("âš ï¸ telegram_bot module not found. Telegram push disabled.")


# ==================== GOOGLE DRIVE SCOPE ====================
GDRIVE_SCOPES = ['https://www.googleapis.com/auth/drive.file']
GDRIVE_TOKEN_FILE = 'drive_token.json'  # Separate token file for Drive

def upload_to_drive(file_path, folder_id):
    """Upload file lÃªn Drive dÃ¹ng drive_token.json hoáº·c táº¡o token má»›i"""
    if not os.path.exists(file_path):
        logging.error(f"âŒ File khÃ´ng tá»“n táº¡i Ä‘á»ƒ upload: {file_path}")
        return None

    logging.info(f"â˜ï¸  Äang upload lÃªn Drive: {os.path.basename(file_path)}...")

    creds = None
    
    # Try to load existing Drive token
    if os.path.exists(GDRIVE_TOKEN_FILE):
        try:
            creds = Credentials.from_authorized_user_file(GDRIVE_TOKEN_FILE, GDRIVE_SCOPES)
        except Exception as e:
            logging.warning(f"âš ï¸ Token file invalid: {e}")
            creds = None
    
    # Refresh or get new credentials
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            try:
                from google.auth.transport.requests import Request
                creds.refresh(Request())
                logging.info("ğŸ”„ Refreshed Drive credentials")
            except Exception as e:
                logging.warning(f"âš ï¸ Could not refresh Drive token: {e}")
                creds = None
        
        if not creds:
            # Need to create new token - check for client_secrets.json
            if os.path.exists('client_secrets.json'):
                try:
                    from google_auth_oauthlib.flow import InstalledAppFlow
                    flow = InstalledAppFlow.from_client_secrets_file('client_secrets.json', GDRIVE_SCOPES)
                    creds = flow.run_local_server(port=8080)
                    logging.info("âœ… New Drive credentials obtained")
                except Exception as e:
                    logging.error(f"âŒ Could not create Drive credentials: {e}")
                    return None
            else:
                logging.error("âŒ KhÃ´ng tÃ¬m tháº¥y client_secrets.json! KhÃ´ng thá»ƒ upload.")
                return None
        
        # Save credentials for next time
        if creds:
            with open(GDRIVE_TOKEN_FILE, 'w') as token:
                token.write(creds.to_json())
            logging.info(f"ğŸ’¾ Saved Drive credentials to {GDRIVE_TOKEN_FILE}")

    try:
        service = build('drive', 'v3', credentials=creds)
        file_metadata = {
            'name': os.path.basename(file_path),
            'parents': [folder_id]
        }
        media = MediaFileUpload(file_path, resumable=True)
        file = service.files().create(
            body=file_metadata,
            media_body=media,
            fields='id'
        ).execute()

        logging.info(f"âœ… Upload thÃ nh cÃ´ng! File ID: {file.get('id')}")
        return file.get('id')

    except Exception as e:
        logging.error(f"âŒ Lá»—i khi upload lÃªn Drive: {e}")
        return None


# ==================== DIRECTORY & ENV ====================
OUTPUT_DIR = "topik-video/public"
ASSETS_DIR = "topik-video/public/assets"
TEMP_DIR   = "temp_processing"

for _d in [OUTPUT_DIR, ASSETS_DIR, TEMP_DIR]:
    os.makedirs(_d, exist_ok=True)

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY", "")

# ==================== AZURE TTS CONFIGURATION ====================
AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY", "")
AZURE_SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION", "eastasia")

# Voice assignment for different roles (Korean only)
AZURE_VOICE_CONFIG = {
    "host": "ko-KR-SunHiNeural",       # Dáº«n chÆ°Æ¡ng trÃ¬nh & News (ná»¯, thÃ¢n thiá»‡n)
    "news": "ko-KR-SunHiNeural",       # News Reader (ná»¯, healing vibes)
    "exam": "ko-KR-InJoonNeural",      # Äá» thi (nam, nghiÃªm tÃºc)
    "analysis": "ko-KR-JiMinNeural",   # Giáº£i thÃ­ch/PhÃ¢n tÃ­ch (ná»¯, chuyÃªn nghiá»‡p)
    "teaching": "ko-KR-InJoonNeural",  # Giáº£ng dáº¡y (nam, dá»©t khoÃ¡t)
}

RSS_SOURCES = [
    {"name": "Donga Editorial",    "url": "https://rss.donga.com/editorial.xml"},
    {"name": "Hankyoreh Opinion",  "url": "http://www.hani.co.kr/rss/opinion/"},
    {"name": "MK News Editorial",  "url": "https://www.mk.co.kr/rss/30000001/"}
]

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

# ==================== 5-VIDEO RENDER MANIFEST ====================
# Mapping: video_key â†’ (CompositionID, output_filename_prefix)
VIDEO_MANIFEST = [
    {"key": "video_1_news",         "composition": "TikTok-NewsHealing",    "prefix": "V1_News",     "audio": "v1_news.mp3"},
    {"key": "video_2_outline",      "composition": "TikTok-WritingCoach",   "prefix": "V2_Writing",  "audio": "v2_outline.mp3"},
    {"key": "video_3_vocab_quiz",   "composition": "TikTok-VocabQuiz",      "prefix": "V3_Vocab",    "audio": "v3_vocab_quiz.mp3"},
    {"key": "video_4_grammar_quiz", "composition": "TikTok-GrammarQuiz",    "prefix": "V4_Grammar",  "audio": "v4_grammar_quiz.mp3"},
    {"key": "video_5_deep_dive",    "composition": "YouTube-DeepDive",      "prefix": "V5_DeepDive", "audio": "v5_deep_dive.mp3"},
]


# ==============================================================================
# 1. HELPER / UTILITY FUNCTIONS  (Giá»¯ nguyÃªn logic gá»‘c)
# ==============================================================================

def call_ai_api(prompt, temperature=0.7):
    """Gá»i Gemini API â†’ tráº£ vá» dict (JSON Ä‘Ã£ parse sáº¡ch)."""
    if not GEMINI_API_KEY:
        logging.error("âŒ ChÆ°a cÃ³ GEMINI_API_KEY!")
        return {}

    url = (
        "https://generativelanguage.googleapis.com/v1beta/"
        f"models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    )
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": temperature,
            "responseMimeType": "application/json"
        }
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=200)
        if response.status_code != 200:
            logging.error(f"API Error: {response.text}")
            return {}

        result   = response.json()
        raw_text = result['candidates'][0]['content']['parts'][0]['text']

        # --- LÃ m sáº¡ch Markdown wrapper ---
        if "```json" in raw_text:
            raw_text = raw_text.split("```json")[1].split("```")[0]
        elif "```" in raw_text:
            raw_text = raw_text.split("```")[1].split("```")[0]

        clean_json = raw_text.strip()
        return json.loads(clean_json)

    except json.JSONDecodeError as e:
        logging.warning(f"âš ï¸  JSON lá»—i nháº¹, Ä‘ang thá»­ sá»­a... ({e})")
        try:
            match = re.search(r"\{.*\}", raw_text, re.DOTALL)
            if match:
                return json.loads(match.group(0))
        except Exception:
            logging.error(f"âŒ KHÃ”NG THá»‚ Sá»¬A JSON. Raw: {raw_text[:200]}...")
            return {}
    except Exception as e:
        logging.error(f"âŒ Lá»—i há»‡ thá»‘ng AI: {e}")
        return {}


def get_latest_editorial_rss():
    """TÃ¬m bÃ i editorial má»›i nháº¥t tá»« RSS â†’ tráº£ vá» (url, source_name)."""
    logging.info("ğŸ” Äang tÃ¬m bÃ i bÃ¡o xÃ£ luáº­n tá»« RSS feeds...")
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    for source in RSS_SOURCES:
        try:
            logging.info(f"   Äang thá»­: {source['name']}...")
            response = requests.get(source['url'], headers=headers, timeout=10)

            try:
                soup = BeautifulSoup(response.content, 'xml')
            except Exception:
                soup = BeautifulSoup(response.content, 'html.parser')

            item = soup.find('item')
            if item:
                link = item.find('link').text.strip()
                title = item.find('title').text.strip()
                logging.info(f"âœ… TÃ¬m tháº¥y: {title[:50]}... tá»« {source['name']}")
                return link, source['name']
        except Exception as e:
            logging.warning(f"   Lá»—i vá»›i {source['name']}: {e}")
            continue

    return None, None


def extract_content(url_input):
    """Táº£i ná»™i dung bÃ i bÃ¡o tá»« URL â†’ tráº£ vá» dict {title, text, url}."""
    if isinstance(url_input, (tuple, list)):
        url = url_input[0]
    else:
        url = url_input

    url = str(url).strip()
    logging.info(f"ğŸ“¥ Äang táº£i: {url}")

    headers = {
        'User-Agent': (
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
            'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ),
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.encoding == 'ISO-8859-1':
            response.encoding = response.apparent_encoding

        soup = BeautifulSoup(response.text, 'html.parser')

        selectors = ['div.text', '#article_view', '.article_txt', '.art_txt', 'article', '#news_body_id']
        main_div = None
        for sel in selectors:
            main_div = soup.select_one(sel)
            if main_div:
                break

        if main_div:
            paragraphs = main_div.find_all('p')
            text_list = [p.get_text().strip() for p in paragraphs if len(p.get_text()) > 20]
        else:
            paragraphs = soup.find_all('p')
            text_list = [p.get_text().strip() for p in paragraphs if len(p.get_text()) > 50]

        article_text = "\n".join(text_list)

        if len(article_text) < 200:
            logging.warning("âš ï¸  Ná»™i dung quÃ¡ ngáº¯n.")
            return None

        title = soup.title.string if soup.title else "News"
        return {'title': title, 'text': article_text, 'url': url}

    except Exception as e:
        logging.error(f"âŒ Lá»—i táº£i bÃ i: {e}")
        return None


def get_video_duration(file_path: str) -> float:
    """
    Get video duration in seconds using ffprobe (if available) or Pexels API data.
    
    Args:
        file_path: Path to the video file
        
    Returns:
        Duration in seconds (float), or 0.0 if unable to detect
    """
    if not os.path.exists(file_path):
        logging.warning(f"âš ï¸ Video file not found: {file_path}")
        return 0.0
    
    # Try using ffprobe (comes with ffmpeg)
    try:
        result = subprocess.run(
            [
                "ffprobe", "-v", "error", 
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                file_path
            ],
            capture_output=True, text=True, timeout=30
        )
        if result.returncode == 0 and result.stdout.strip():
            duration = float(result.stdout.strip())
            logging.info(f"ğŸ“¹ Video duration: {duration:.2f}s (from ffprobe)")
            return duration
    except (subprocess.TimeoutExpired, FileNotFoundError, ValueError) as e:
        logging.debug(f"ffprobe not available or failed: {e}")
    
    # Fallback: estimate from file size (rough approximation)
    # Average TikTok video: ~2MB per 10 seconds at 1080p
    try:
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        estimated_duration = file_size_mb / 0.2  # ~0.2 MB per second rough estimate
        logging.info(f"ğŸ“¹ Video duration: ~{estimated_duration:.1f}s (estimated from file size)")
        return estimated_duration
    except Exception:
        pass
    
    # If all else fails, return 0
    logging.warning(f"âš ï¸ Could not determine video duration for: {file_path}")
    return 0.0


# Global variable to store video background duration
VIDEO_BG_DURATION_CACHE = 0.0


def download_background_video(query, output_path):
    """
    Táº£i video ná»n tá»« Pexels API vÃ  lÆ°u duration.
    
    Returns:
        dict: {"success": bool, "duration": float} or False for backward compatibility
    """
    global VIDEO_BG_DURATION_CACHE
    
    if not PEXELS_API_KEY:
        logging.warning("âš ï¸  Thiáº¿u PEXELS_API_KEY.")
        return False

    clean_query = "".join(e for e in query if e.isalnum() or e.isspace())
    logging.info(f"ğŸ¬ Äang tÃ¬m video ná»n: '{clean_query}'...")

    headers = {"Authorization": PEXELS_API_KEY}
    api_url = (
        f"https://api.pexels.com/videos/search?"
        f"query={clean_query}&per_page=1&orientation=portrait"
    )

    try:
        response = requests.get(api_url, headers=headers, timeout=15)
        data = response.json()
        if not data.get('videos'):
            return False

        video_data  = random.choice(data['videos'])
        video_files = video_data['video_files']
        valid_files = [v for v in video_files if v['width'] and 600 < v['width'] < 1200]
        best_file   = valid_files[0] if valid_files else video_files[0]
        
        # Get duration from Pexels API (available in video_data)
        pexels_duration = video_data.get('duration', 0)

        with requests.get(best_file['link'], stream=True) as r:
            r.raise_for_status()
            with open(output_path, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)

        # Get actual duration from file (more accurate than Pexels API)
        actual_duration = get_video_duration(output_path)
        if actual_duration <= 0:
            actual_duration = pexels_duration  # Fallback to Pexels API duration
        
        VIDEO_BG_DURATION_CACHE = actual_duration
        logging.info(f"âœ… ÄÃ£ táº£i video ná»n! Duration: {actual_duration:.2f}s")
        return {"success": True, "duration": actual_duration}

    except Exception as e:
        logging.error(f"âŒ Lá»—i táº£i video: {e}")
        return False


def sanitize_text(text):
    """Lá»c kÃ½ tá»± lá»—i XML Ä‘á»ƒ trÃ¡nh crash file Word."""
    if not text:
        return ""
    return re.sub(r'[^\x09\x0A\x0D\x20-\uD7FF\uE000-\uFFFD]', '', str(text))


# ==============================================================================
# 2. AZURE TTS FUNCTIONS  â€”  Thay tháº¿ edge-tts (Cháº¥t lÆ°á»£ng cao hÆ¡n)
# ==============================================================================

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SSML Dynamic Rate Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NgÆ°á»¡ng kÃ½ tá»± Ä‘á»ƒ Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™ Ä‘á»c tá»± Ä‘á»™ng
# VÄƒn báº£n dÃ i hÆ¡n sáº½ Ä‘Æ°á»£c Ä‘á»c nhanh hÆ¡n Ä‘á»ƒ khá»›p vá»›i khung hÃ¬nh video
SSML_RATE_THRESHOLDS = {
    "short": {"max_chars": 50, "rate": "+0%"},       # Ngáº¯n: tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng
    "medium": {"max_chars": 150, "rate": "+10%"},   # Trung bÃ¬nh: tÄƒng 10%
    "long": {"max_chars": 300, "rate": "+15%"},     # DÃ i: tÄƒng 15%
    "very_long": {"max_chars": 500, "rate": "+20%"},# Ráº¥t dÃ i: tÄƒng 20%
    "extra_long": {"max_chars": float('inf'), "rate": "+25%"}  # SiÃªu dÃ i: tÄƒng 25%
}

# Target max duration for TikTok videos (seconds)
TIKTOK_MAX_DURATION = 55  # Target < 60s, aim for 55s
TIKTOK_COMPRESS_RATE = "+15%"  # Rate to apply when total > 55s


def estimate_reading_time(text: str, chars_per_second: float = 5.0) -> float:
    """
    Estimate reading time in seconds based on text length.
    Korean typically reads at ~4-6 characters per second.
    
    Args:
        text: Korean text
        chars_per_second: Reading speed (default 5.0 for Korean)
        
    Returns:
        Estimated duration in seconds
    """
    if not text:
        return 0.0
    return len(text.strip()) / chars_per_second


def should_compress_audio(total_text: str, target_max: float = TIKTOK_MAX_DURATION) -> tuple[bool, str]:
    """
    Check if audio should be compressed based on estimated duration.
    
    If estimated reading time > target_max seconds, return True with +15% rate.
    
    Args:
        total_text: Combined Korean text for the video
        target_max: Maximum allowed duration in seconds
        
    Returns:
        Tuple of (should_compress: bool, rate: str)
    """
    estimated = estimate_reading_time(total_text)
    
    if estimated > target_max:
        logging.info(f"âš¡ Auto-compress: Estimated {estimated:.1f}s > {target_max}s â†’ applying {TIKTOK_COMPRESS_RATE}")
        return True, TIKTOK_COMPRESS_RATE
    else:
        return False, "+0%"


def _calculate_dynamic_rate(text: str, base_rate: str = "+0%") -> str:
    """
    Calculate dynamic speech rate based on text length.
    
    VÄƒn báº£n dÃ i hÆ¡n sáº½ Ä‘Æ°á»£c Ä‘á»c nhanh hÆ¡n Ä‘á»ƒ nÃ©n thá»i gian Ä‘á»c,
    giÃºp khá»›p vá»›i khung hÃ¬nh video mÃ  váº«n giá»¯ cháº¥t lÆ°á»£ng tá»± nhiÃªn.
    
    Args:
        text: Korean text to synthesize
        base_rate: Base rate specified by caller (e.g., "-10%", "+5%")
        
    Returns:
        Final rate string (e.g., "+15%")
    """
    text_length = len(text.strip())
    
    # Determine rate based on text length
    dynamic_rate_value = 0
    for tier_name, config in SSML_RATE_THRESHOLDS.items():
        if text_length <= config["max_chars"]:
            rate_str = config["rate"]
            dynamic_rate_value = int(rate_str.replace("%", "").replace("+", ""))
            break
    
    # Parse base rate
    base_rate_clean = base_rate.replace("%", "")
    if base_rate_clean.startswith("+"):
        base_rate_value = int(base_rate_clean[1:])
    elif base_rate_clean.startswith("-"):
        base_rate_value = int(base_rate_clean)
    else:
        base_rate_value = int(base_rate_clean) if base_rate_clean else 0
    
    # Combine rates (additive)
    final_rate_value = base_rate_value + dynamic_rate_value
    
    # Clamp to reasonable range (-50% to +50%)
    final_rate_value = max(-50, min(50, final_rate_value))
    
    # Format as string
    if final_rate_value >= 0:
        return f"+{final_rate_value}%"
    else:
        return f"{final_rate_value}%"


def _build_ssml(text: str, voice_name: str, rate: str, use_dynamic_rate: bool = True) -> str:
    """
    Build SSML markup with prosody rate adjustment.
    
    Args:
        text: Korean text to synthesize
        voice_name: Azure voice name
        rate: Base rate (will be adjusted dynamically if use_dynamic_rate=True)
        use_dynamic_rate: Whether to apply dynamic rate based on text length
        
    Returns:
        Complete SSML string
    """
    # Calculate final rate
    if use_dynamic_rate:
        final_rate = _calculate_dynamic_rate(text, rate)
    else:
        final_rate = rate
    
    # Clean up rate format for SSML
    rate_value = final_rate.replace("%", "")
    if not rate_value.startswith("+") and not rate_value.startswith("-"):
        rate_value = f"+{rate_value}"
    
    # Escape special XML characters in text
    escaped_text = (text
        .replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )
    
    # Build SSML with breaks for natural pauses
    ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">
    <voice name="{voice_name}">
        <prosody rate="{rate_value}%">
            {escaped_text}
        </prosody>
    </voice>
</speak>"""
    
    return ssml


def generate_azure_tts(text: str, voice_name: str, output_path: str, rate: str = "+0%", use_dynamic_rate: bool = True) -> float:
    """
    Generate TTS audio using Azure Cognitive Services Speech SDK.
    
    Uses SSML with dynamic prosody rate adjustment:
    - VÄƒn báº£n ngáº¯n (< 50 chars): tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng
    - VÄƒn báº£n trung bÃ¬nh (50-150 chars): +10%
    - VÄƒn báº£n dÃ i (150-300 chars): +15%
    - VÄƒn báº£n ráº¥t dÃ i (300-500 chars): +20%
    - VÄƒn báº£n siÃªu dÃ i (> 500 chars): +25%
    
    Args:
        text: Korean text to synthesize (KHÃ”NG táº¡o audio cho tiáº¿ng Viá»‡t!)
        voice_name: Azure voice name (e.g., "ko-KR-SunHiNeural")
        output_path: Path to save the MP3 file
        rate: Base speed rate (e.g., "-10%", "+0%", "+10%")
        use_dynamic_rate: Whether to apply dynamic rate based on text length
        
    Returns:
        Duration in seconds (float), or 0.0 if failed
        
    RULE: CHá»ˆ táº¡o audio cho tiáº¿ng HÃ n. Tiáº¿ng Viá»‡t dÃ¹ng lÃ m phá»¥ Ä‘á», khÃ´ng cÃ³ audio.
    """
    if not text or not text.strip():
        return 0.0
    
    # Check for Vietnamese text and REMOVE Vietnamese portions instead of skipping entirely
    # This handles cases where explanation_ko contains mixed Korean/Vietnamese
    vietnamese_pattern = r'[Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]'
    if re.search(vietnamese_pattern, text.lower()):
        # Remove Vietnamese portions: text in single quotes like 'nguyÃªn nhÃ¢n chÃ­nh cá»§a viá»‡c...'
        # Also remove explanations in parentheses containing Vietnamese
        cleaned_text = re.sub(r"'[^']*[Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘][^']*'", "", text)
        cleaned_text = re.sub(r"\([^)]*[Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘][^)]*\)", "", cleaned_text)
        # Clean up multiple spaces and orphaned punctuation
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        cleaned_text = re.sub(r'\s+([.,])', r'\1', cleaned_text)
        
        if cleaned_text and len(cleaned_text) > 10:
            logging.info(f"ğŸ”„ Removed Vietnamese from TTS text: '{text[:50]}...' â†’ '{cleaned_text[:50]}...'")
            text = cleaned_text
        else:
            logging.warning(f"âš ï¸ Text mostly Vietnamese, skipping TTS: {text[:50]}...")
            return 0.0
    
    if not AZURE_TTS_AVAILABLE or not AZURE_SPEECH_KEY:
        logging.warning("âš ï¸ Azure TTS not available, falling back to edge-tts...")
        final_rate = _calculate_dynamic_rate(text, rate) if use_dynamic_rate else rate
        return _fallback_edge_tts_sync(text, voice_name, output_path, final_rate)
    
    try:
        # Configure Azure Speech SDK
        speech_config = speechsdk.SpeechConfig(
            subscription=AZURE_SPEECH_KEY,
            region=AZURE_SPEECH_REGION
        )
        speech_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
        )
        speech_config.speech_synthesis_voice_name = voice_name
        
        # Create audio config for file output
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_path)
        
        # Create synthesizer
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config,
            audio_config=audio_config
        )
        
        # Build SSML with dynamic rate adjustment
        ssml = _build_ssml(text, voice_name, rate, use_dynamic_rate)
        
        # Log rate info for debugging
        if use_dynamic_rate:
            final_rate = _calculate_dynamic_rate(text, rate)
            logging.debug(f"ğŸ“¢ SSML rate: {final_rate} (text length: {len(text)} chars)")
        
        # Synthesize
        result = synthesizer.speak_ssml_async(ssml).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            duration = get_audio_duration(output_path)
            logging.debug(f"âœ… Azure TTS OK: {os.path.basename(output_path)} ({duration:.2f}s)")
            return duration
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation = result.cancellation_details
            logging.error(f"âŒ Azure TTS canceled: {cancellation.reason}")
            if cancellation.reason == speechsdk.CancellationReason.Error:
                logging.error(f"   Error details: {cancellation.error_details}")
            # Fallback to edge-tts
            final_rate = _calculate_dynamic_rate(text, rate) if use_dynamic_rate else rate
            return _fallback_edge_tts_sync(text, voice_name, output_path, final_rate)
        else:
            logging.error(f"âŒ Azure TTS failed with reason: {result.reason}")
            final_rate = _calculate_dynamic_rate(text, rate) if use_dynamic_rate else rate
            return _fallback_edge_tts_sync(text, voice_name, output_path, final_rate)
            
    except Exception as e:
        logging.error(f"âŒ Azure TTS exception: {e}")
        final_rate = _calculate_dynamic_rate(text, rate) if use_dynamic_rate else rate
        return _fallback_edge_tts_sync(text, voice_name, output_path, final_rate)


def _fallback_edge_tts_sync(text: str, voice_name: str, output_path: str, rate: str) -> float:
    """Fallback to edge-tts when Azure TTS fails (synchronous wrapper)."""
    if not EDGE_TTS_AVAILABLE:
        logging.error("âŒ Neither Azure TTS nor edge-tts available!")
        return 0.0
    
    try:
        asyncio.run(_tts_to_file(text, voice_name, rate, output_path))
        return get_audio_duration(output_path)
    except Exception as e:
        logging.error(f"âŒ edge-tts fallback failed: {e}")
        return 0.0


async def generate_azure_tts_async(text: str, voice_name: str, output_path: str, rate: str = "+0%", use_dynamic_rate: bool = True) -> float:
    """
    Async version of generate_azure_tts for use in async contexts.
    Wraps the sync function in an executor.
    
    Args:
        text: Korean text to synthesize
        voice_name: Azure voice name
        output_path: Path to save the MP3 file
        rate: Base speed rate
        use_dynamic_rate: Whether to apply dynamic rate based on text length
    """
    import concurrent.futures
    from functools import partial
    
    loop = asyncio.get_event_loop()
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Use partial to pass all arguments including use_dynamic_rate
        func = partial(generate_azure_tts, text, voice_name, output_path, rate, use_dynamic_rate)
        duration = await loop.run_in_executor(executor, func)
    return duration


# ==============================================================================
# 2. AI PIPELINE  â€”  Phase 1 â†’ Phase 2 â†’ Phase 3
# ==============================================================================

def run_phase_1(article_text: str) -> dict:
    """
    Phase 1: PhÃ¢n tÃ­ch bÃ i bÃ¡o â†’ ra Ä‘á» thi TOPIK 54 + tÃ³m táº¯t tin tá»©c.
    Giá»¯ nguyÃªn prompt gá»‘c.
    """
    logging.info("ğŸ§  Phase 1: PhÃ¢n tÃ­ch & Ra Ä‘á»...")

    prompt_p1 = f"""
    Báº¡n lÃ  chuyÃªn gia ra Ä‘á» thi TOPIK II vá»›i hÆ¡n 10 nÄƒm kinh nghiá»‡m.

    Dá»±a trÃªn thÃ´ng tin sau (Ä‘Æ°á»£c trÃ­ch tá»« má»™t báº£n tin xÃ£ há»™i, KHÃ”NG pháº£i Ä‘á» thi):

    [NEWS_SUMMARY]
    {article_text[:3000]}

    HÃ£y thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ sau:

    1. PhÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t Má»˜T "váº¥n Ä‘á» xÃ£ há»™i hoáº·c xu hÆ°á»›ng xÃ£ há»™i" mang tÃ­nh tá»•ng quÃ¡t:
       - KhÃ´ng nháº¯c Ä‘áº¿n thá»i gian cá»¥ thá»ƒ
       - KhÃ´ng nháº¯c Ä‘áº¿n sá»± kiá»‡n hay tÃªn tá»• chá»©c cá»¥ thá»ƒ
       - KhÃ´ng dÃ¹ng vÄƒn phong bÃ¡o chÃ­
       - Pháº£i lÃ  váº¥n Ä‘á» cÃ³ thá»ƒ láº·p láº¡i nhiá»u nÄƒm

    2. Táº¡o Má»˜T Ä‘á» thi viáº¿t TOPIK II â€“ cÃ¢u 54:
       - ÄÃºng vÄƒn phong Ä‘á» thi TOPIK
       - Dáº¡ng tháº£o luáº­n: nguyÃªn nhÃ¢n â†’ tÃ¡c Ä‘á»™ng â†’ giáº£i phÃ¡p
       - KhÃ´ng dÃ¹ng sá»‘ liá»‡u chi tiáº¿t
       - KhÃ´ng quÃ¡ thá»i sá»±

    3. TÃ³m táº¯t cÆ¡ báº£n ná»™i dung bÃ i bÃ¡o báº±ng TIáº¾NG HÃ€N ÄÆ N GIáº¢N (Level TOPIK 3) Ä‘á»ƒ lÃ m báº£n tin dá»… nghe.

    âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG:
       - Tuyá»‡t Ä‘á»‘i KHÃ”NG nháº¯c Ä‘áº¿n nguá»“n tin, bÃ¡o chÃ­ hay tÃªn tá»• chá»©c
       - Pháº£i khiáº¿n ngÆ°á»i há»c cáº£m giÃ¡c Ä‘Ã¢y lÃ  Ä‘á» thi tháº­t Ä‘Ã£ tá»«ng ra
       - VÄƒn phong pháº£i giá»‘ng 90% Ä‘á» TOPIK tháº­t

    ğŸ“‹ Cáº¤U TRÃšC Äá»€ BÃ€I CHUáº¨N TOPIK 54:

    ë‹¤ìŒì„ ì£¼ì œë¡œ í•˜ì—¬ ìì‹ ì˜ ìƒê°ì„ 600~700ìë¡œ ê¸€ì„ ì“°ì‹­ì‹œì˜¤. (30ì )

    [2-3 cÃ¢u má»Ÿ Ä‘áº§u giá»›i thiá»‡u váº¥n Ä‘á» xÃ£ há»™i, khÃ´ng nháº¯c nguá»“n]

    <ì¡°ê±´>
    â€¢ [NguyÃªn nhÃ¢n cá»§a váº¥n Ä‘á»]
    â€¢ [TÃ¡c Ä‘á»™ng/áº£nh hÆ°á»Ÿng cá»§a váº¥n Ä‘á»]
    â€¢ [Giáº£i phÃ¡p hoáº·c hÆ°á»›ng Ä‘i tÆ°Æ¡ng lai]

    OUTPUT JSON (STRICT FORMAT):
    {{
        "topic_korean": "Chá»§ Ä‘á» chÃ­nh (tiáº¿ng HÃ n)",
        "video_keyword": "tá»« khÃ³a tÃ¬m video ná»n",
        "news_summary_easy_kr": "TÃ³m táº¯t tin tá»©c thÃ nh chá»§ Ä‘á» Ä‘Æ¡n giáº£n (Tiáº¿ng HÃ n)",
        "question_full_text": "Äá» thi TOPIK 54 Ä‘áº§y Ä‘á»§ (Giá»¯ nguyÃªn Ä‘á»™ khÃ³ cao cáº¥p)"
    }}
    """

    data_p1 = call_ai_api(prompt_p1, temperature=0.5)
    if not data_p1:
        logging.error("âŒ Phase 1 tháº¥t báº¡i â€” khÃ´ng cÃ³ dá»¯ liá»‡u.")
        return {}

    logging.info(f"ğŸ”¹ Chá»§ Ä‘á»: {data_p1.get('topic_korean', 'N/A')}")
    return data_p1


def run_phase_2(data_p1: dict) -> dict:
    """
    Phase 2: Viáº¿t vÄƒn máº«u + phÃ¢n tÃ­ch tá»« vá»±ng & ngá»¯ phÃ¡p.
    Giá»¯ nguyÃªn prompt gá»‘c.
    """
    logging.info("ğŸ§  Phase 2: Viáº¿t vÄƒn máº«u...")

    prompt_p2 = f"""
    Role: You are the Head Grader of the TOPIK II Writing Section (ì“°ê¸° ì±„ì  ìœ„ì›ì¥).
    Input Question & Conditions: {data_p1['question_full_text']}

    OBJECTIVE: Write a model essay (ëª¨ë²” ë‹µì•ˆ) that receives a PERFECT SCORE (50/50).

    --- ğŸ›‘ STRICT WRITING RULES (DO NOT IGNORE) ---
    1.  **FORMAT**:
        -   Total length: 600-700 characters (No more, no less).
        -   Structure: EXACTLY 4 Paragraphs.
            -   Para 1: Introduction (Generalize the issue).
            -   Para 2: Response to Bullet Point 1.
            -   Para 3: Response to Bullet Point 2.
            -   Para 4: Response to Bullet Point 3 + Conclusion.

    2.  **TONE & STYLE**:
        -   **Video Style**: Highly Academic & Formal (í•™ìˆ ì  ê¸€ì“°ê¸°).
        -   **Ending**: STRICTLY use '-ë‹¤/ëŠ”ë‹¤' style. (NEVER use -ìŠµë‹ˆë‹¤/í•´ìš”).
        -   **Perspective**: Objective. Do NOT use "I" (ì €/ë‚˜/ì œ ìƒê°ì—ëŠ”). Use "It is considered that..." (ì—¬ê²¨ì§„ë‹¤) or "We" (ìš°ë¦¬).
        -   **Banned Phrases**: 'ê²ƒ ê°™ë‹¤' (seems like), 'ì•Œ ìˆ˜ ìˆë‹¤' (can know). -> REPLACE WITH: 'ë¶„ëª…í•˜ë‹¤' (clear), 'íŒŒì•…ëœë‹¤' (identified).

    3.  **ADVANCED VOCABULARY INJECTION**:
        -   Must use at least 2 **Four-character Idioms (ì‚¬ìì„±ì–´)** (e.g., ì„¤ìƒê°€ìƒ, ì—­ì§€ì‚¬ì§€, ìœ ë¹„ë¬´í™˜...).
        -   Must use **Advanced Connectors**:
            -   Start Para 2 with: ìš°ì„  / ë¬´ì—‡ë³´ë‹¤ë„...
            -   Start Para 3 with: í•˜ì§€ë§Œ / ë°˜ë©´ì— / ì´ì™€ ë”ë¶ˆì–´...
            -   Start Para 4 with: ë”°ë¼ì„œ / ê²°ë¡ ì ìœ¼ë¡œ...

    --- TASK LIST ---

    TASK 1: Write the Essay.

    TASK 2: Vocabulary Extraction (Korean -> Vietnamese).
    (Tuyá»‡t Ä‘á»‘i khÃ´ng thÃªm HÃ¡n tá»± trong ngoáº·c Ä‘Æ¡n á»Ÿ pháº§n "word")
    -   Select all "Tier 1" academic words from the essay (e.g., phenomenon, implementation, countermeasure).

    TASK 3: Grammar Analysis.
    -   Explain all advanced grammar points used.

    OUTPUT JSON STRUCTURE:
    {{
        "essay": "Korean text...",
        "analysis_list": [
            {{ "item": "All vocabulary advanced from the essay", "professor_explanation": "Lá»i giáº£ng cá»§a giÃ¡o sÆ° vá» sáº¯c thÃ¡i/cÃ¡ch dÃ¹ng..." }},
            {{ "item": "All grammar points from the essay", "professor_explanation": "..." }}
        ]
    }}
    """

    data_p2 = call_ai_api(prompt_p2, temperature=0.7)
    if not data_p2:
        logging.error("âŒ Phase 2 tháº¥t báº¡i â€” khÃ´ng cÃ³ dá»¯ liá»‡u.")
        return {}

    logging.info(f"ğŸ”¹ Essay length: {len(data_p2.get('essay', ''))} chars")
    return data_p2



def run_phase_3(data_p1: dict, data_p2: dict) -> dict:
    """
    Phase 3 â€” BIÃŠN Táº¬P VIÃŠN ÄA KÃŠNH (Multi-Channel Editor).

    Input:  data_p1 (News + Äá» thi), data_p2 (Essay + Analysis)
    Output: JSON cáº¥u trÃºc cho 4 video TikTok + dá»¯ liá»‡u Word doc.

    RULE: Korean Audio - Vietnamese Subtitles
    NEW: Má»—i video cÃ³ opening_ment (lá»i chÃ o tiáº¿ng HÃ n)
    """
    logging.info("ğŸ§  Phase 3: BiÃªn táº­p viÃªn Ä‘a kÃªnh â€” cáº¥u trÃºc 4 video TikTok...")

    analysis_str = json.dumps(data_p2.get('analysis_list', []), ensure_ascii=False)

    prompt_p3 = f"""
    Báº¡n lÃ  "BiÃªn táº­p viÃªn Ä‘a kÃªnh" (Multi-Channel Content Editor) chuyÃªn táº¡o ná»™i dung há»c tiáº¿ng HÃ n cho TikTok.

    â›” NGUYÃŠN Táº®C Cá»T LÃ•I:
    1. CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« Dá»® LIá»†U Äáº¦U VÃ€O dÆ°á»›i Ä‘Ã¢y. KhÃ´ng tá»± Ã½ sÃ¡ng táº¡o ná»™i dung má»›i.
    2. KhÃ´ng thay Ä‘á»•i ná»™i dung bÃ i vÄƒn máº«u hay Ä‘á» thi gá»‘c.
    3. CÃ¡c cÃ¢u há»i tráº¯c nghiá»‡m (Quiz) pháº£i dá»±a Ä‘Ãºng vÃ o tá»« vá»±ng/ngá»¯ phÃ¡p Ä‘Ã£ cÃ³ trong 'PhÃ¢n tÃ­ch cá»§a GiÃ¡o sÆ°'.
    4. Má»—i script pháº£i Äá»¦ NGáº®N Ä‘á»ƒ Ä‘á»c trong 30â€“45 giÃ¢y (phÃ¹ há»£p TikTok).

    ğŸ¯ LUáº¬T Báº®T BUá»˜C: KOREAN AUDIO - VIETNAMESE SUBTITLES
    - Táº¥t cáº£ audio sáº½ Ä‘Æ°á»£c Ä‘á»c báº±ng TIáº¾NG HÃ€N.
    - Tiáº¿ng Viá»‡t CHá»ˆ dÃ¹ng lÃ m phá»¥ Ä‘á» hiá»ƒn thá»‹ trÃªn mÃ n hÃ¬nh.
    - Má»—i video pháº£i tÃ¡ch rÃµ: "audio_text" (HÃ n) vÃ  "segments" (cáº·p ko/vi).

    ğŸ¤ Ká»ŠCH Báº¢N Lá»œI CHÃ€O (OPENING_MENT) + Káº¾T THÃšC (CLOSING_MENT) - LIÃŠN Káº¾T 4 VIDEO:
    
    âš¡ QUAN TRá»ŒNG: 4 video short pháº£i LIÃŠN Káº¾T vá»›i nhau nhÆ° má»™t series!
    - Video 1 â†’ má»Ÿ Ä‘áº§u series hÃ´m nay, káº¿t thÃºc dáº«n sang Video 2
    - Video 2 â†’ ná»‘i tiáº¿p tá»« Video 1, káº¿t thÃºc dáº«n sang Video 3  
    - Video 3 â†’ ná»‘i tiáº¿p tá»« Video 2, káº¿t thÃºc dáº«n sang Video 4
    - Video 4 â†’ ná»‘i tiáº¿p tá»« Video 3, káº¿t thÃºc khÃ©p láº¡i series hÃ´m nay
    
    ğŸ“Œ OPENING_MENT (má»Ÿ Ä‘áº§u ~3-5 giÃ¢y):
    - Video 1: "ì•ˆë…•í•˜ì„¸ìš”! ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ í•œêµ­ ì‚¬íšŒ ì´ìŠˆ, í•¨ê»˜ ë“¤ì–´ë³¼ê¹Œìš”?"
    - Video 2: "ì, ì´ì–´ì„œ! ë°©ê¸ˆ ë°°ìš´ ì£¼ì œë¡œ í† í”½ ì“°ê¸° ì—°ìŠµì„ í•´ë³¼ê¹Œìš”?"
    - Video 3: "ì´ì œ ì–´íœ˜ í€´ì¦ˆ ì‹œê°„ì…ë‹ˆë‹¤! ì¤€ë¹„ëë‚˜ìš”?"
    - Video 4: "ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¸ë²• í€´ì¦ˆì…ë‹ˆë‹¤! í•œë²ˆ ë„ì „í•´ë³¼ê¹Œìš”?"
    
    ğŸ“Œ CLOSING_MENT (káº¿t thÃºc ~3-5 giÃ¢y):
    - Video 1: "ë‹¤ìŒ ì˜ìƒì—ì„œ ì“°ê¸° ì—°ìŠµ í•¨ê»˜ í•´ë´ìš”!"
    - Video 2: "ë‹¤ìŒ ì˜ìƒì—ì„œ ì–´íœ˜ í€´ì¦ˆ í’€ì–´ë´ìš”!"
    - Video 3: "ë‹¤ìŒ ì˜ìƒì—ì„œ ë¬¸ë²• í€´ì¦ˆë„ ë„ì „í•´ë´ìš”!"
    - Video 4: "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í–ˆì–´ìš”! ë‚´ì¼ ë˜ ë§Œë‚˜ìš”, ì•ˆë…•!"

    --- Dá»® LIá»†U Äáº¦U VÃ€O (SOURCE DATA) ---

    1. [TÃ“M Táº®T TIN Tá»¨C (Tiáº¿ng HÃ n Ä‘Æ¡n giáº£n)]:
    {data_p1.get('news_summary_easy_kr', '')}

    2. [Äá»€ THI Gá»C TOPIK 54]:
    {data_p1.get('question_full_text', '')}

    3. [VÄ‚N MáºªU CHUáº¨N (4 Ä‘oáº¡n)]:
    {data_p2.get('essay', '')}

    4. [PHÃ‚N TÃCH Cá»¦A GIÃO SÆ¯ (Tá»« vá»±ng + Ngá»¯ phÃ¡p)]:
    {analysis_str}

    --- YÃŠU Cáº¦U OUTPUT ---
    Tráº£ vá» 1 JSON duy nháº¥t vá»›i cáº¥u trÃºc CHÃNH XÃC sau:

    {{
        "meta": {{
            "topic_title_vi": "TiÃªu Ä‘á» tiáº¿ng Viá»‡t háº¥p dáº«n (dÆ°á»›i 10 tá»«)"
        }},

        "word_doc_data": {{
            "vocab_list": [
                {{"word": "tá»« vá»±ng", "meaning_vi": "nghÄ©a tiáº¿ng Viá»‡t", "example": "1 cÃ¢u vÃ­ dá»¥ ngáº¯n chá»©a tá»« nÃ y"}}
            ],
            "grammar_list": [
                {{"point": "Ä‘iá»ƒm ngá»¯ phÃ¡p", "meaning_vi": "nghÄ©a", "example": "1 cÃ¢u vÃ­ dá»¥ ngáº¯n"}}
            ],
            "cloze_test": {{
                "question": "TrÃ­ch 1 cÃ¢u hay nháº¥t tá»« [VÄ‚N MáºªU CHUáº¨N], thay tá»« khÃ³a báº±ng [ ___ ]",
                "answer": "tá»« khÃ³a bá»‹ che",
                "hint_vi": "gá»£i Ã½ nghÄ©a tiáº¿ng Viá»‡t"
            }}
        }},

        "tiktok_script": {{
            "video_1_news": {{
                // Giá»ng ná»¯ nháº¹ nhÃ ng â€” Healing vibes
                // Viáº¿t láº¡i [TÃ“M Táº®T TIN Tá»¨C] theo phong cÃ¡ch thá»§ thá»‰, tÃ¢m tÃ¬nh.
                // Káº¿t báº±ng cÃ¢u há»i gá»£i má»Ÿ: "Náº¿u thi vÃ o chá»§ Ä‘á» nÃ y thÃ¬ sao?"
                "opening_ment": "ì•ˆë…•í•˜ì„¸ìš”! ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ í•œêµ­ ì‚¬íšŒ ì´ìŠˆ, í•¨ê»˜ ë“¤ì–´ë³¼ê¹Œìš”?",
                "audio_text": "ToÃ n bá»™ text tiáº¿ng HÃ n Ä‘á»ƒ TTS Ä‘á»c (20-30 giÃ¢y, KHÃ”NG bao gá»“m opening_ment)",
                "closing_ment": "ë‹¤ìŒ ì˜ìƒì—ì„œ ì“°ê¸° ì—°ìŠµ í•¨ê»˜ í•´ë´ìš”!",
                "segments": [
                    {{"ko": "CÃ¢u tiáº¿ng HÃ n 1", "vi": "Dá»‹ch tiáº¿ng Viá»‡t 1"}},
                    {{"ko": "CÃ¢u tiáº¿ng HÃ n 2", "vi": "Dá»‹ch tiáº¿ng Viá»‡t 2"}},
                    {{"ko": "CÃ¢u tiáº¿ng HÃ n 3", "vi": "Dá»‹ch tiáº¿ng Viá»‡t 3"}}
                ]
            }},
            "video_2_outline": {{
                // Giá»ng nam giÃ¡o sÆ° â€” Teaching vibes
                // TÃ³m táº¯t cáº¥u trÃºc bÃ i vÄƒn máº«u thÃ nh 4 pháº§n.
                "opening_ment": "ì, ì´ì–´ì„œ! ë°©ê¸ˆ ë°°ìš´ ì£¼ì œë¡œ í† í”½ ì“°ê¸° ì—°ìŠµì„ í•´ë³¼ê¹Œìš”?",
                "audio_text": "ToÃ n bá»™ text tiáº¿ng HÃ n Ä‘á»ƒ TTS Ä‘á»c (25-35 giÃ¢y, KHÃ”NG bao gá»“m opening_ment)",
                "closing_ment": "ë‹¤ìŒ ì˜ìƒì—ì„œ ì–´íœ˜ í€´ì¦ˆ í’€ì–´ë´ìš”!",
                "parts": [
                    {{
                        "role": "intro",
                        "label_vi": "Má»Ÿ BÃ i",
                        "ko": "Luáº­n Ä‘iá»ƒm tiáº¿ng HÃ n cho pháº§n má»Ÿ bÃ i",
                        "vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t ngáº¯n gá»n"
                    }},
                    {{
                        "role": "body_1",
                        "label_vi": "ThÃ¢n BÃ i 1 - NguyÃªn nhÃ¢n",
                        "ko": "Luáº­n Ä‘iá»ƒm tiáº¿ng HÃ n",
                        "vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t"
                    }},
                    {{
                        "role": "body_2",
                        "label_vi": "ThÃ¢n BÃ i 2 - TÃ¡c Ä‘á»™ng",
                        "ko": "Luáº­n Ä‘iá»ƒm tiáº¿ng HÃ n",
                        "vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t"
                    }},
                    {{
                        "role": "body_3",
                        "label_vi": "Káº¿t BÃ i - Giáº£i phÃ¡p",
                        "ko": "Luáº­n Ä‘iá»ƒm tiáº¿ng HÃ n",
                        "vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t"
                    }}
                ]
            }},
            "video_3_vocab_quiz": {{
                // Game show: Äá»c cÃ¢u há»i â†’ Im láº·ng 4s â†’ ÄÃ¡p Ã¡n + Giáº£i thÃ­ch
                // Chá»n 1 tá»« KHÃ“ NHáº¤T tá»« [PHÃ‚N TÃCH Cá»¦A GIÃO SÆ¯] Ä‘á»ƒ há»i.
                "opening_ment": "ì´ì œ ì–´íœ˜ í€´ì¦ˆ ì‹œê°„ì…ë‹ˆë‹¤! ì¤€ë¹„ëë‚˜ìš”?",
                "target_word": "tá»« vá»±ng Ä‘Æ°á»£c chá»n Ä‘á»ƒ há»i",
                "question_ko": "CÃ¢u há»i tráº¯c nghiá»‡m báº±ng tiáº¿ng HÃ n (~5 giÃ¢y Ä‘á»c)",
                "question_vi": "Dá»‹ch cÃ¢u há»i sang tiáº¿ng Viá»‡t",
                "options_ko": ["A. ÄÃ¡p Ã¡n HÃ n 1", "B. ÄÃ¡p Ã¡n HÃ n 2", "C. ÄÃ¡p Ã¡n HÃ n 3", "D. ÄÃ¡p Ã¡n HÃ n 4"],
                "options_vi": ["A. Dá»‹ch Viá»‡t 1", "B. Dá»‹ch Viá»‡t 2", "C. Dá»‹ch Viá»‡t 3", "D. Dá»‹ch Viá»‡t 4"],
                "correct_answer": "C",
                "explanation_ko": "Giáº£i thÃ­ch tiáº¿ng HÃ n ngáº¯n gá»n (~8 giÃ¢y Ä‘á»c)",
                "explanation_vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t chi tiáº¿t hÆ¡n",
                "closing_ment": "ë‹¤ìŒ ì˜ìƒì—ì„œ ë¬¸ë²• í€´ì¦ˆë„ ë„ì „í•´ë´ìš”!"
            }},
            "video_4_grammar_quiz": {{
                // Game show: Äá»c cÃ¢u há»i â†’ Im láº·ng 4s â†’ ÄÃ¡p Ã¡n + Giáº£i thÃ­ch
                // Chá»n 1 Ä‘iá»ƒm ngá»¯ phÃ¡p HAY NHáº¤T tá»« [PHÃ‚N TÃCH Cá»¦A GIÃO SÆ¯].
                "opening_ment": "ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¸ë²• í€´ì¦ˆì…ë‹ˆë‹¤! í•œë²ˆ ë„ì „í•´ë³¼ê¹Œìš”?",
                "target_grammar": "Ä‘iá»ƒm ngá»¯ phÃ¡p Ä‘Æ°á»£c chá»n Ä‘á»ƒ há»i",
                "question_ko": "CÃ¢u há»i Ä‘iá»n ngá»¯ phÃ¡p vÃ o chá»— trá»‘ng báº±ng tiáº¿ng HÃ n (~5 giÃ¢y Ä‘á»c)",
                "question_vi": "Dá»‹ch cÃ¢u há»i sang tiáº¿ng Viá»‡t",
                "options_ko": ["A. ÄÃ¡p Ã¡n HÃ n 1", "B. ÄÃ¡p Ã¡n HÃ n 2", "C. ÄÃ¡p Ã¡n HÃ n 3", "D. ÄÃ¡p Ã¡n HÃ n 4"],
                "options_vi": ["A. Dá»‹ch Viá»‡t 1", "B. Dá»‹ch Viá»‡t 2", "C. Dá»‹ch Viá»‡t 3", "D. Dá»‹ch Viá»‡t 4"],
                "correct_answer": "C",
                "explanation_ko": "Giáº£i thÃ­ch tiáº¿ng HÃ n ngáº¯n gá»n (~8 giÃ¢y Ä‘á»c)",
                "explanation_vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t chi tiáº¿t hÆ¡n",
                "closing_ment": "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í–ˆì–´ìš”! ë‚´ì¼ ë˜ ë§Œë‚˜ìš”, ì•ˆë…•!"
            }}
        }}
    }}
    """

    data_p3 = call_ai_api(prompt_p3, temperature=0.7)
    if not data_p3:
        logging.error("âŒ Phase 3 tháº¥t báº¡i â€” khÃ´ng cÃ³ dá»¯ liá»‡u.")
        return {}

    logging.info(f"ğŸ”¹ Topic (VI): {data_p3.get('meta', {}).get('topic_title_vi', 'N/A')}")
    logging.info("âœ… Phase 3 hoÃ n thÃ nh â€” 4 video scripts (Korean Audio) + word_doc_data OK")
    return data_p3


def run_phase_4(data_p1: dict, data_p2: dict, data_p3: dict) -> dict:
    """
    Phase 4 â€” DEEP DIVE EPISODE (YouTube Long-form Video).
    
    Input:  data_p1 (News + Äá» thi), data_p2 (Essay + Analysis), data_p3 (TikTok scripts)
    Output: JSON cáº¥u trÃºc cho video_5_deep_dive vá»›i cÃ¡c section chi tiáº¿t.
    
    RULE: Korean Audio - Vietnamese Subtitles
    Thá»i lÆ°á»£ng má»¥c tiÃªu: 5-10 phÃºt (YouTube format)
    """
    logging.info("ğŸ§  Phase 4: Deep Dive Episode â€” Ká»‹ch báº£n YouTube dÃ i...")

    analysis_str = json.dumps(data_p2.get('analysis_list', []), ensure_ascii=False)
    essay_text = data_p2.get('essay', '')
    vocab_data = data_p3.get('word_doc_data', {}).get('vocab_list', [])
    grammar_data = data_p3.get('word_doc_data', {}).get('grammar_list', [])
    
    vocab_str = json.dumps(vocab_data, ensure_ascii=False)
    grammar_str = json.dumps(grammar_data, ensure_ascii=False)

    prompt_p4 = f"""
    Báº¡n lÃ  biÃªn táº­p viÃªn chÆ°Æ¡ng trÃ¬nh "DAILY KOREAN" (ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆ) trÃªn YouTube.
    
    â›” NGUYÃŠN Táº®C Cá»T LÃ•I (Báº®T BUá»˜C):
    1. Audio sáº½ Ä‘á»c 100% báº±ng TIáº¾NG HÃ€N.
    2. Tiáº¿ng Viá»‡t CHá»ˆ dÃ¹ng lÃ m PHá»¤ Äá»€ hiá»ƒn thá»‹ trÃªn mÃ n hÃ¬nh.
    3. Thá»i lÆ°á»£ng video má»¥c tiÃªu: 5-10 phÃºt (YouTube format).
    4. Má»—i segment pháº£i cÃ³ placeholder "duration_sec": 0 (sáº½ Ä‘Æ°á»£c tÃ­nh sau khi táº¡o audio).
    
    ğŸš¨ QUAN TRá»ŒNG - QUY Táº®C NGÃ”N NGá»®:
    - Táº¥t cáº£ cÃ¡c field káº¿t thÃºc báº±ng "_ko" (nhÆ° explanation_ko, example_ko, analysis_ko) 
      PHáº¢I VIáº¾T 100% Báº°NG TIáº¾NG HÃ€N THUáº¦N TÃšY.
    - TUYá»†T Äá»I KHÃ”NG Ä‘Æ°á»£c trá»™n tiáº¿ng Viá»‡t vÃ o cÃ¡c field "_ko".
    - Tiáº¿ng Viá»‡t CHá»ˆ Ä‘Æ°á»£c viáº¿t trong cÃ¡c field káº¿t thÃºc báº±ng "_vi".
    
    VÃ­ dá»¥ ÄÃšNG:
    - "explanation_ko": "ì´ ë‹¨ì–´ëŠ” ê¸‰ê²©í•œ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ì…ë‹ˆë‹¤. ì‚¬íšŒë‚˜ í™˜ê²½ì´ ë¹ ë¥´ê²Œ ë³€í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    - "meaning_vi": "Diá»…n táº£ sá»± thay Ä‘á»•i nhanh chÃ³ng, Ä‘á»™t ngá»™t"
    
    VÃ­ dá»¥ SAI (âŒ KHÃ”NG LÃ€M):
    - "explanation_ko": "ê¸‰ë³€í•˜ë‹¤. Diá»…n táº£ sá»± thay Ä‘á»•i nhanh chÃ³ng..."  â† CÃ³ tiáº¿ng Viá»‡t!
    
    --- Dá»® LIá»†U Äáº¦U VÃ€O ---
    
    1. [TIN Tá»¨C Gá»C]: {data_p1.get('news_summary_easy_kr', '')}
    
    2. [Äá»€ THI TOPIK 54]: {data_p1.get('question_full_text', '')}
    
    3. [VÄ‚N MáºªU CHUáº¨N]: {essay_text}
    
    4. [PHÃ‚N TÃCH Cá»¦A GIÃO SÆ¯]: {analysis_str}
    
    5. [DANH SÃCH Tá»ª Vá»°NG]: {vocab_str}
    
    6. [DANH SÃCH NGá»® PHÃP]: {grammar_str}
    
    --- YÃŠU Cáº¦U OUTPUT ---
    
    Táº¡o ká»‹ch báº£n DEEP DIVE cho YouTube vá»›i 7 section chi tiáº¿t.
    Má»—i section pháº£i cÃ³:
    - "ko": Text tiáº¿ng HÃ n Ä‘á»ƒ TTS Ä‘á»c (100% TIáº¾NG HÃ€N, KHÃ”NG trá»™n tiáº¿ng Viá»‡t)
    - "vi": Phá»¥ Ä‘á» tiáº¿ng Viá»‡t tÆ°Æ¡ng á»©ng
    - "duration_sec": 0 (placeholder)
    
    OUTPUT JSON (STRICT FORMAT):
    {{
        "video_5_deep_dive": {{
            "meta": {{
                "title_ko": "í† í”½ 54ë²ˆ ì™„ë²½ ë¶„ì„ - ì˜¤ëŠ˜ì˜ í•œêµ­ ì‚¬íšŒ ì´ìŠˆ (TIáº¾NG HÃ€N)",
                "title_vi": "PhÃ¢n tÃ­ch Ä‘á» TOPIK 54 - Váº¥n Ä‘á» xÃ£ há»™i HÃ n Quá»‘c hÃ´m nay",
                "description_vi": "MÃ´ táº£ ngáº¯n cho YouTube (~100 tá»« tiáº¿ng Viá»‡t)",
                "hashtags": ["#TOPIK", "#KoreanLearning", "#í† í”½ì“°ê¸°", "...thÃªm 5-7 hashtag"]
            }},
            
            "opening": {{
                "hook_ko": "ì—¬ëŸ¬ë¶„, í† í”½ ì“°ê¸° 54ë²ˆ ë¬¸ì œ, ì–´ë–»ê²Œ ì¤€ë¹„í•˜ê³  ê³„ì„¸ìš”? (TIáº¾NG HÃ€N ~10 giÃ¢y)",
                "hook_vi": "CÃ¡c báº¡n Æ¡i, Ä‘á» TOPIK 54, cÃ¡c báº¡n chuáº©n bá»‹ tháº¿ nÃ o rá»“i?",
                "intro_ko": "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€ ìµœì‹  ì‚¬íšŒ ì´ìŠˆì™€ í† í”½ ì“°ê¸° 54ë²ˆì„ í•¨ê»˜ ë¶„ì„í•´ ë³´ê² ìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N ~20 giÃ¢y)",
                "intro_vi": "Xin chÃ o, hÃ´m nay chÃºng ta sáº½ cÃ¹ng phÃ¢n tÃ­ch tin tá»©c xÃ£ há»™i vÃ  Ä‘á» TOPIK 54.",
                "duration_sec": 0
            }},
            
            "news": {{
                "transition_ko": "ë¨¼ì € ì˜¤ëŠ˜ì˜ í•œêµ­ ì‚¬íšŒ ì´ìŠˆë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N)",
                "transition_vi": "Äáº§u tiÃªn chÃºng ta cÃ¹ng xem tin tá»©c xÃ£ há»™i hÃ´m nay.",
                "content_ko": "Äá»c/viáº¿t láº¡i tin tá»©c báº±ng TIáº¾NG HÃ€N Ä‘Æ¡n giáº£n (~30-45 giÃ¢y, láº¥y tá»« input)",
                "content_vi": "Dá»‹ch tin tá»©c sang tiáº¿ng Viá»‡t",
                "analysis_ko": "ì´ ë‰´ìŠ¤ì—ì„œ ì¤‘ìš”í•œ ì ì€... (PhÃ¢n tÃ­ch báº±ng TIáº¾NG HÃ€N ~30 giÃ¢y)",
                "analysis_vi": "Äiá»ƒm quan trá»ng trong tin nÃ y lÃ ...",
                "duration_sec": 0
            }},
            
            "transition": {{
                "bridge_ko": "ì´ ì£¼ì œê°€ ë°”ë¡œ í† í”½ 54ë²ˆê³¼ ì—°ê²°ë©ë‹ˆë‹¤. (TIáº¾NG HÃ€N ~15 giÃ¢y)",
                "bridge_vi": "Chá»§ Ä‘á» nÃ y liÃªn quan trá»±c tiáº¿p Ä‘áº¿n Ä‘á» TOPIK 54.",
                "duration_sec": 0
            }},
            
            "exam": {{
                "intro_ko": "ì´ì œ í† í”½ 54ë²ˆ ë¬¸ì œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N)",
                "intro_vi": "BÃ¢y giá» chÃºng ta cÃ¹ng xem Ä‘á» TOPIK 54.",
                "question_ko": "Láº¥y Ä‘á» thi tá»« input vÃ  viáº¿t báº±ng TIáº¾NG HÃ€N (~45-60 giÃ¢y)",
                "question_vi": "Dá»‹ch Ä‘á» thi Ä‘áº§y Ä‘á»§ sang tiáº¿ng Viá»‡t",
                "tips_ko": "í† í”½ ì“°ê¸°ì—ì„œ ì¤‘ìš”í•œ ì ì€ ì²«ì§¸... ë‘˜ì§¸... ì…‹ì§¸... (3 tips báº±ng TIáº¾NG HÃ€N)",
                "tips_vi": "Äiá»ƒm quan trá»ng khi viáº¿t TOPIK lÃ  thá»© nháº¥t... thá»© hai... thá»© ba...",
                "duration_sec": 0
            }},
            
            "essay": {{
                "intro_ko": "ì´ì œ ëª¨ë²” ë‹µì•ˆì„ í•¨ê»˜ ì½ì–´ë³´ê² ìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N - giá»›i thiá»‡u bÃ i vÄƒn máº«u)",
                "intro_vi": "BÃ¢y giá» chÃºng ta cÃ¹ng Ä‘á»c bÃ i vÄƒn máº«u.",
                "paragraphs": [
                    {{
                        "label": "ì„œë¡  (Má»Ÿ bÃ i)",
                        "ko": "Ná»™i dung má»Ÿ bÃ i báº±ng TIáº¾NG HÃ€N (láº¥y tá»« VÄ‚N MáºªU)",
                        "vi": "Dá»‹ch sang tiáº¿ng Viá»‡t",
                        "analysis_ko": "ì´ ì„œë¡ ì—ì„œëŠ”... (PhÃ¢n tÃ­ch ká»¹ thuáº­t viáº¿t báº±ng TIáº¾NG HÃ€N)",
                        "analysis_vi": "Trong pháº§n má»Ÿ bÃ i nÃ y..."
                    }},
                    {{
                        "label": "ë³¸ë¡  1 (ThÃ¢n bÃ i 1)",
                        "ko": "Ná»™i dung thÃ¢n bÃ i 1 báº±ng TIáº¾NG HÃ€N",
                        "vi": "Dá»‹ch",
                        "analysis_ko": "ì²« ë²ˆì§¸ ë³¸ë¡ ì—ì„œëŠ”... (TIáº¾NG HÃ€N)",
                        "analysis_vi": "Trong thÃ¢n bÃ i 1..."
                    }},
                    {{
                        "label": "ë³¸ë¡  2 (ThÃ¢n bÃ i 2)",
                        "ko": "Ná»™i dung thÃ¢n bÃ i 2 báº±ng TIáº¾NG HÃ€N",
                        "vi": "Dá»‹ch",
                        "analysis_ko": "ë‘ ë²ˆì§¸ ë³¸ë¡ ì—ì„œëŠ”... (TIáº¾NG HÃ€N)",
                        "analysis_vi": "Trong thÃ¢n bÃ i 2..."
                    }},
                    {{
                        "label": "ê²°ë¡  (Káº¿t bÃ i)",
                        "ko": "Ná»™i dung káº¿t bÃ i báº±ng TIáº¾NG HÃ€N",
                        "vi": "Dá»‹ch",
                        "analysis_ko": "ê²°ë¡ ì—ì„œëŠ”... (TIáº¾NG HÃ€N)",
                        "analysis_vi": "Trong pháº§n káº¿t..."
                    }}
                ],
                "duration_sec": 0
            }},
            
            "vocab": {{
                "intro_ko": "ì´ì œ ì˜¤ëŠ˜ ë°°ìš´ ì¤‘ìš”í•œ ì–´íœ˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N thuáº§n tÃºy)",
                "intro_vi": "BÃ¢y giá» chÃºng ta cÃ¹ng xem qua tá»« vá»±ng quan trá»ng nhÃ©.",
                "items": [
                    {{
                        "word": "ê¸‰ë³€í•˜ë‹¤",
                        "explanation_ko": "ì´ ë‹¨ì–´ëŠ” ê¸‰ê²©í•œ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ì…ë‹ˆë‹¤. ì‚¬íšŒë‚˜ í™˜ê²½ì´ ë¹ ë¥´ê²Œ ë³€í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (100% TIáº¾NG HÃ€N)",
                        "meaning_vi": "Thay Ä‘á»•i nhanh chÃ³ng, biáº¿n Ä‘á»•i Ä‘á»™t ngá»™t",
                        "example_ko": "ì„¸ê³„ ê²½ì œê°€ ê¸‰ë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤. (100% TIáº¾NG HÃ€N)",
                        "example_vi": "Kinh táº¿ tháº¿ giá»›i Ä‘ang thay Ä‘á»•i nhanh chÃ³ng."
                    }}
                ],
                "grammar_items": [
                    {{
                        "point": "-ë¡œ ì¸í•´",
                        "explanation_ko": "ì´ í‘œí˜„ì€ ì›ì¸ì´ë‚˜ ì´ìœ ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì–´ë–¤ ì¼ì˜ ì›ì¸ì„ ì„¤ëª…í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (100% TIáº¾NG HÃ€N)",
                        "meaning_vi": "Do, vÃ¬ (nguyÃªn nhÃ¢n)",
                        "example_ko": "ì½”ë¡œë‚˜ë¡œ ì¸í•´ ë§ì€ ë³€í™”ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. (100% TIáº¾NG HÃ€N)",
                        "example_vi": "Do corona, Ä‘Ã£ cÃ³ nhiá»u thay Ä‘á»•i."
                    }}
                ],
                "duration_sec": 0
            }},
            
            "closing": {{
                "summary_ko": "ì˜¤ëŠ˜ì€ í† í”½ 54ë²ˆ ë¬¸ì œì™€ ê´€ë ¨ëœ ë‚´ìš©ì„ í•¨ê»˜ ê³µë¶€í–ˆìŠµë‹ˆë‹¤. (TIáº¾NG HÃ€N - tÃ³m táº¯t ~20 giÃ¢y)",
                "summary_vi": "HÃ´m nay chÃºng ta Ä‘Ã£ cÃ¹ng há»c vá» Ä‘á» TOPIK 54.",
                "cta_ko": "ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì€ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”! (TIáº¾NG HÃ€N)",
                "cta_vi": "Náº¿u video há»¯u Ã­ch, hÃ£y like vÃ  subscribe nhÃ©. CÃ³ tháº¯c máº¯c gÃ¬ Ä‘á»ƒ láº¡i comment!",
                "outro_ko": "ë‹¤ìŒ ì˜ìƒì—ì„œ ë˜ ë§Œë‚˜ìš”! ì•ˆë…•íˆ ê³„ì„¸ìš”! (TIáº¾NG HÃ€N)",
                "outro_vi": "Háº¹n gáº·p láº¡i á»Ÿ video tiáº¿p theo! Táº¡m biá»‡t!",
                "duration_sec": 0
            }}
        }}
    }}
    """

    data_p4 = call_ai_api(prompt_p4, temperature=0.7)
    if not data_p4:
        logging.error("âŒ Phase 4 tháº¥t báº¡i â€” khÃ´ng cÃ³ dá»¯ liá»‡u.")
        return {}

    logging.info("âœ… Phase 4 hoÃ n thÃ nh â€” Deep Dive Episode script OK")
    return data_p4


# ==============================================================================
# 3. TIKTOK AUDIO ASSET GENERATION  â€”  Segment-based MP3 generation
# ==============================================================================

# Cáº¥u hÃ¬nh giá»ng Ä‘á»c & tá»‘c Ä‘á»™ cho tá»«ng video
# RULE: Chá»‰ sá»­ dá»¥ng giá»ng tiáº¿ng HÃ n
# Updated to use Azure voice names from AZURE_VOICE_CONFIG
_VOICE_CFG = {
    "video_1": {"voice": "ko-KR-SunHiNeural",   "rate": "-10%",  "role": "news"},      # Healing â€” ná»¯, cháº­m
    "video_2": {"voice": "ko-KR-InJoonNeural",  "rate": "+0%",   "role": "teaching"},  # Teaching â€” nam
    "video_3": {"voice": "ko-KR-InJoonNeural",  "rate": "+0%",   "role": "exam"},      # Quiz â€” nam
    "video_4": {"voice": "ko-KR-InJoonNeural",  "rate": "+0%",   "role": "exam"},      # Quiz â€” nam
    "video_5": {"voice": "ko-KR-JiMinNeural",   "rate": "+0%",   "role": "analysis"},  # Deep Dive â€” ná»¯
}

# Thá»i gian im láº·ng cho pháº§n "suy nghÄ©" trong Quiz (milliseconds)
QUIZ_SILENCE_MS = 4000   # 4 giÃ¢y


def get_audio_duration(file_path: str) -> float:
    """
    Get audio duration in seconds using mutagen (accurate) or pydub (fallback).
    
    Args:
        file_path: Path to the MP3 file
        
    Returns:
        Duration in seconds (float)
    """
    if not os.path.exists(file_path):
        logging.warning(f"âš ï¸ Audio file not found: {file_path}")
        return 0.0
    
    try:
        if MUTAGEN_AVAILABLE:
            audio = MP3(file_path)
            return audio.info.length
        else:
            # Fallback to pydub
            audio = AudioSegment.from_file(file_path, format="mp3")
            return len(audio) / 1000.0
    except Exception as e:
        logging.error(f"âŒ Error getting audio duration for {file_path}: {e}")
        return 0.0


async def _tts_to_file(text: str, voice: str, rate: str, output_path: str) -> float:
    """
    Generate TTS audio and save directly to file, return duration.
    
    Args:
        text: Korean text to synthesize
        voice: Edge TTS voice name
        rate: Speed rate (e.g., "-10%", "+0%")
        output_path: Path to save the MP3 file
        
    Returns:
        Duration in seconds (float)
    """
    if not text or not text.strip():
        return 0.0
    
    try:
        communicate = edge_tts.Communicate(text.strip(), voice, rate=rate)
        await communicate.save(output_path)
        duration = get_audio_duration(output_path)
        return duration
    except Exception as e:
        logging.error(f"âŒ TTS generation failed: {e}")
        return 0.0


async def _tts_to_segment(text: str, voice: str, rate: str) -> AudioSegment:
    """
    Async helper: Gá»i edge_tts â†’ lÆ°u táº¡m â†’ Ä‘á»c vá» AudioSegment â†’ xÃ³a file táº¡m.
    RULE: text PHáº¢I lÃ  tiáº¿ng HÃ n.
    """
    if not text or not text.strip():
        return AudioSegment.empty()

    tmp_path = os.path.join(
        TEMP_DIR,
        f"_tts_{int(time.time() * 1000)}_{random.randint(1, 99999)}.mp3"
    )

    communicate = edge_tts.Communicate(text.strip(), voice, rate=rate)
    await communicate.save(tmp_path)

    segment = AudioSegment.from_file(tmp_path, format="mp3")

    # Cleanup
    if os.path.exists(tmp_path):
        os.remove(tmp_path)

    return segment


async def _build_video1_news(script: dict, assets_dir: str) -> dict:
    """
    Video 1 â€” News Healing.
    
    NEW STRUCTURE: opening_ment â†’ content â†’ closing_ment
    Generate separate audio files for each phase with precise timing.
    Auto-compress with SSML +15% if total estimated duration > 55s.
    
    Returns:
        dict with structure:
        {
            "opening": {"audio_path": "/assets/...", "duration": 3.5, "text": "..."},
            "segments": [
                {"ko": "...", "vi": "...", "audio_path": "/assets/...", "duration": 2.5},
                ...
            ],
            "closing": {"audio_path": "/assets/...", "duration": 2.0, "text": "..."},
            "total_duration": 12.5,
            "combined_audio": "/assets/v1_news.mp3"
        }
    """
    cfg = _VOICE_CFG["video_1"]
    
    # Extract script parts
    opening_ment = script.get("opening_ment", "")
    closing_ment = script.get("closing_ment", "ë‹¤ìŒ ì˜ìƒì—ì„œ ë˜ ë§Œë‚˜ìš”!")
    segments = script.get("segments", [])
    audio_text = script.get("audio_text", "")
    
    # Fallback: if no segments, use audio_text as single segment
    if not segments and audio_text:
        segments = [{"ko": audio_text, "vi": ""}]
    
    if not segments and not opening_ment:
        logging.warning("âš ï¸  Video 1: No content found â€” skipping.")
        return {"segments": [], "total_duration": 0, "combined_audio": None}
    
    # Calculate total text for auto-compress check
    total_text = opening_ment + " " + " ".join(s.get("ko", "") for s in segments) + " " + closing_ment
    should_compress, compress_rate = should_compress_audio(total_text)
    base_rate = compress_rate if should_compress else cfg["rate"]
    
    result = {
        "opening": None,
        "segments": [],
        "closing": None,
        "total_duration": 0.0,
        "combined_audio": None,
        "ssml_compressed": should_compress
    }
    
    combined_audio = AudioSegment.empty()
    total_duration = 0.0
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 1: Opening Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if opening_ment:
        opening_path = os.path.join(assets_dir, "v1_opening.mp3")
        duration = generate_azure_tts(opening_ment, cfg["voice"], opening_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["opening"] = {
                "audio_path": "/assets/v1_opening.mp3",
                "duration": round(duration, 3),
                "text": opening_ment
            }
            total_duration += duration
            
            if os.path.exists(opening_path):
                combined_audio += AudioSegment.from_file(opening_path, format="mp3")
                combined_audio += AudioSegment.silent(duration=300)  # 0.3s pause
                total_duration += 0.3
            
            logging.info(f"ğŸµ V1 Opening: v1_opening.mp3 ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 2: Content Segments
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for idx, seg in enumerate(segments):
        ko_text = seg.get("ko", "")
        vi_text = seg.get("vi", "")
        
        if not ko_text:
            continue
        
        seg_filename = f"v1_seg_{idx}.mp3"
        seg_path = os.path.join(assets_dir, seg_filename)
        
        duration = generate_azure_tts(ko_text, cfg["voice"], seg_path, base_rate, use_dynamic_rate=True)
        
        if duration > 0:
            result["segments"].append({
                "ko": ko_text,
                "vi": vi_text,
                "audio_path": f"/assets/{seg_filename}",
                "duration": round(duration, 3)
            })
            total_duration += duration
            
            if os.path.exists(seg_path):
                combined_audio += AudioSegment.from_file(seg_path, format="mp3")
            
            logging.info(f"ğŸµ V1 Segment {idx}: {seg_filename} ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 3: Closing Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if closing_ment:
        closing_path = os.path.join(assets_dir, "v1_closing.mp3")
        duration = generate_azure_tts(closing_ment, cfg["voice"], closing_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["closing"] = {
                "audio_path": "/assets/v1_closing.mp3",
                "duration": round(duration, 3),
                "text": closing_ment
            }
            
            if os.path.exists(closing_path):
                combined_audio += AudioSegment.silent(duration=300)  # 0.3s pause before closing
                combined_audio += AudioSegment.from_file(closing_path, format="mp3")
                total_duration += duration + 0.3
            
            logging.info(f"ğŸµ V1 Closing: v1_closing.mp3 ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMBINED AUDIO (backward compatibility)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    combined_path = os.path.join(assets_dir, "v1_news.mp3")
    if len(combined_audio) > 0:
        combined_audio.export(combined_path, format="mp3")
        # Re-measure actual duration
        actual_duration = get_audio_duration(combined_path)
        result["total_duration"] = round(actual_duration, 3)
        result["combined_audio"] = "/assets/v1_news.mp3"
        logging.info(f"ğŸµ Video 1 combined: v1_news.mp3 ({actual_duration:.1f}s total)")
    else:
        result["total_duration"] = round(total_duration, 3)
    
    return result


async def _build_video2_outline(script: dict, assets_dir: str) -> dict:
    """
    Video 2 â€” Writing Coach.
    
    NEW STRUCTURE: opening_ment â†’ parts â†’ closing_ment
    Generate separate audio files for each phase with precise timing.
    Auto-compress with SSML +15% if total estimated duration > 55s.
    
    Returns:
        dict with structure:
        {
            "opening": {"audio_path": "/assets/...", "duration": 3.2, "text": "..."},
            "parts": [
                {"role": "intro", "ko": "...", "vi": "...", "audio_path": "/assets/...", "duration": 3.2},
                {"role": "body_1", ...},
                {"role": "body_2", ...},
                {"role": "body_3", ...}
            ],
            "closing": {"audio_path": "/assets/...", "duration": 2.0, "text": "..."},
            "total_duration": 15.5,
            "combined_audio": "/assets/v2_outline.mp3"
        }
    """
    cfg = _VOICE_CFG["video_2"]
    
    # Extract script parts
    opening_ment = script.get("opening_ment", "")
    closing_ment = script.get("closing_ment", "ë‹¤ìŒ ì˜ìƒì—ì„œ ë˜ ë§Œë‚˜ìš”!")
    parts = script.get("parts", [])
    
    # If no parts, try to build from legacy format
    if not parts:
        legacy_roles = ["intro", "body_1", "body_2", "conclusion"]
        for role in legacy_roles:
            text = script.get(role, "")
            if text:
                parts.append({"role": role, "ko": text, "vi": ""})
    
    if not parts and not opening_ment:
        logging.warning("âš ï¸  Video 2: No parts found â€” skipping.")
        return {"parts": [], "total_duration": 0, "combined_audio": None}
    
    # Calculate total text for auto-compress check
    total_text = opening_ment + " " + " ".join(p.get("ko", "") for p in parts) + " " + closing_ment
    should_compress, compress_rate = should_compress_audio(total_text)
    base_rate = compress_rate if should_compress else cfg["rate"]
    
    result = {
        "opening": None,
        "parts": [],
        "closing": None,
        "total_duration": 0.0,
        "combined_audio": None,
        "ssml_compressed": should_compress
    }
    
    combined_audio = AudioSegment.empty()
    total_duration = 0.0
    pause = AudioSegment.silent(duration=500)  # 0.5s between parts
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 1: Opening Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if opening_ment:
        opening_path = os.path.join(assets_dir, "v2_opening.mp3")
        duration = generate_azure_tts(opening_ment, cfg["voice"], opening_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["opening"] = {
                "audio_path": "/assets/v2_opening.mp3",
                "duration": round(duration, 3),
                "text": opening_ment
            }
            total_duration += duration
            
            if os.path.exists(opening_path):
                combined_audio += AudioSegment.from_file(opening_path, format="mp3")
                combined_audio += pause
                total_duration += 0.5
            
            logging.info(f"ğŸµ V2 Opening: v2_opening.mp3 ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 2: Content Parts (Intro, Body1, Body2, Body3/Conclusion)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for idx, part in enumerate(parts):
        role = part.get("role", f"part_{idx}")
        ko_text = part.get("ko", "")
        vi_text = part.get("vi", "")
        label_vi = part.get("label_vi", "")
        
        if not ko_text:
            continue
        
        part_filename = f"v2_{role}.mp3"
        part_path = os.path.join(assets_dir, part_filename)
        
        duration = generate_azure_tts(ko_text, cfg["voice"], part_path, base_rate, use_dynamic_rate=True)
        
        if duration > 0:
            result["parts"].append({
                "role": role,
                "label_vi": label_vi,
                "ko": ko_text,
                "vi": vi_text,
                "audio_path": f"/assets/{part_filename}",
                "duration": round(duration, 3)
            })
            total_duration += duration
            
            if os.path.exists(part_path):
                combined_audio += AudioSegment.from_file(part_path, format="mp3")
                if idx < len(parts) - 1:
                    combined_audio += pause
                    total_duration += 0.5
            
            logging.info(f"ğŸµ V2 {role}: {part_filename} ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 3: Closing Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if closing_ment:
        closing_path = os.path.join(assets_dir, "v2_closing.mp3")
        duration = generate_azure_tts(closing_ment, cfg["voice"], closing_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["closing"] = {
                "audio_path": "/assets/v2_closing.mp3",
                "duration": round(duration, 3),
                "text": closing_ment
            }
            
            if os.path.exists(closing_path):
                combined_audio += pause
                combined_audio += AudioSegment.from_file(closing_path, format="mp3")
                total_duration += duration + 0.5
            
            logging.info(f"ğŸµ V2 Closing: v2_closing.mp3 ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMBINED AUDIO (backward compatibility)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    combined_path = os.path.join(assets_dir, "v2_outline.mp3")
    if len(combined_audio) > 0:
        combined_audio.export(combined_path, format="mp3")
        actual_duration = get_audio_duration(combined_path)
        result["total_duration"] = round(actual_duration, 3)
        result["combined_audio"] = "/assets/v2_outline.mp3"
        logging.info(f"ğŸµ Video 2 combined: v2_outline.mp3 ({actual_duration:.1f}s total)")
    else:
        result["total_duration"] = round(total_duration, 3)
    
    return result


async def _build_quiz_audio(script: dict, assets_dir: str, video_key: str) -> dict:
    """
    Video 3 & 4 â€” Quiz (Vocab / Grammar).
    
    NEW STRUCTURE: opening_ment â†’ question â†’ [silence 4s] â†’ answer â†’ closing_ment
    Split audio into separate files for precise Remotion control.
    Auto-compress with SSML +15% if total estimated duration > 55s.
    
    Returns:
        dict with structure:
        {
            "opening_audio": {"path": "/assets/...", "duration": 3.0, "text": "..."},
            "question_audio": {"path": "/assets/...", "duration": 5.2},
            "answer_audio": {"path": "/assets/...", "duration": 8.1},
            "closing_audio": {"path": "/assets/...", "duration": 2.0, "text": "..."},
            "silence_duration": 4.0,
            "total_duration": 22.3,
            "combined_audio": "/assets/v3_vocab_quiz.mp3"
        }
    """
    cfg = _VOICE_CFG[video_key]
    video_num = video_key.split("_")[1]  # "3" or "4"
    
    # Extract data
    opening_ment = script.get("opening_ment", "")
    closing_ment = script.get("closing_ment", "ë‹¤ìŒ í€´ì¦ˆì—ì„œ ë˜ ë§Œë‚˜ìš”!")
    question_ko = script.get("question_ko") or script.get("question", "")
    options_ko = script.get("options_ko") or script.get("options", [])
    correct = script.get("correct_answer", "")
    explanation_ko = script.get("explanation_ko") or script.get("explanation", "")
    
    if not question_ko:
        logging.warning(f"âš ï¸  {video_key}: question_ko rá»—ng â€” skipping.")
        return {
            "opening_audio": None,
            "question_audio": None,
            "answer_audio": None,
            "closing_audio": None,
            "silence_duration": QUIZ_SILENCE_MS / 1000.0,
            "total_duration": 0,
            "combined_audio": None
        }
    
    # Calculate total text for auto-compress check
    total_text = (opening_ment + " " + question_ko + " " + " ".join(options_ko) + 
                  " " + f"ì •ë‹µì€ {correct}ì…ë‹ˆë‹¤. " + explanation_ko + " " + closing_ment)
    should_compress, compress_rate = should_compress_audio(total_text)
    base_rate = compress_rate if should_compress else cfg["rate"]
    
    result = {
        "opening_audio": None,
        "question_audio": None,
        "answer_audio": None,
        "closing_audio": None,
        "silence_duration": QUIZ_SILENCE_MS / 1000.0,
        "total_duration": 0,
        "combined_audio": None,
        "ssml_compressed": should_compress
    }
    
    combined_audio = AudioSegment.empty()
    total_duration = 0.0
    short_pause = AudioSegment.silent(duration=300)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 0: Opening Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if opening_ment:
        opening_filename = f"v{video_num}_opening.mp3"
        opening_path = os.path.join(assets_dir, opening_filename)
        duration = generate_azure_tts(opening_ment, cfg["voice"], opening_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["opening_audio"] = {
                "path": f"/assets/{opening_filename}",
                "duration": round(duration, 3),
                "text": opening_ment
            }
            total_duration += duration
            
            if os.path.exists(opening_path):
                combined_audio += AudioSegment.from_file(opening_path, format="mp3")
                combined_audio += short_pause
                total_duration += 0.3
            
            logging.info(f"ğŸµ {video_key} opening: {opening_filename} ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 1: Question Audio (Question + Options)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    q_filename = f"v{video_num}_question.mp3"
    q_path = os.path.join(assets_dir, q_filename)
    
    # Build question audio: Question + short pause + Options
    q_audio = await _tts_to_segment(question_ko, cfg["voice"], base_rate)
    
    options_text = "  ".join(options_ko)
    opt_audio = await _tts_to_segment(options_text, cfg["voice"], base_rate)
    
    question_combined = q_audio + short_pause + opt_audio
    question_combined.export(q_path, format="mp3")
    q_duration = get_audio_duration(q_path)
    
    result["question_audio"] = {
        "path": f"/assets/{q_filename}",
        "duration": round(q_duration, 3)
    }
    total_duration += q_duration
    combined_audio += question_combined
    
    logging.info(f"ğŸµ {video_key} question: {q_filename} ({q_duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SILENCE (4 seconds) - Added to combined, Remotion handles separately
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    silence = AudioSegment.silent(duration=QUIZ_SILENCE_MS)
    combined_audio += silence
    total_duration += QUIZ_SILENCE_MS / 1000.0
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 2: Answer Audio (Answer announcement + Explanation)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    a_filename = f"v{video_num}_answer.mp3"
    a_path = os.path.join(assets_dir, a_filename)
    
    answer_announce = f"ì •ë‹µì€ {correct}ì…ë‹ˆë‹¤."
    ans_audio = await _tts_to_segment(answer_announce, cfg["voice"], base_rate)
    expl_audio = await _tts_to_segment(explanation_ko, cfg["voice"], base_rate)
    
    answer_combined = ans_audio + short_pause + expl_audio
    answer_combined.export(a_path, format="mp3")
    a_duration = get_audio_duration(a_path)
    
    result["answer_audio"] = {
        "path": f"/assets/{a_filename}",
        "duration": round(a_duration, 3)
    }
    total_duration += a_duration
    combined_audio += answer_combined
    
    logging.info(f"ğŸµ {video_key} answer: {a_filename} ({a_duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART 3: Closing Ment
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if closing_ment:
        closing_filename = f"v{video_num}_closing.mp3"
        closing_path = os.path.join(assets_dir, closing_filename)
        duration = generate_azure_tts(closing_ment, cfg["voice"], closing_path, base_rate, use_dynamic_rate=False)
        
        if duration > 0:
            result["closing_audio"] = {
                "path": f"/assets/{closing_filename}",
                "duration": round(duration, 3),
                "text": closing_ment
            }
            
            if os.path.exists(closing_path):
                combined_audio += short_pause
                combined_audio += AudioSegment.from_file(closing_path, format="mp3")
                total_duration += duration + 0.3
            
            logging.info(f"ğŸµ {video_key} closing: {closing_filename} ({duration:.2f}s)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMBINED AUDIO (backward compatibility)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    combined_filename = f"v{video_num}_{'vocab' if video_num == '3' else 'grammar'}_quiz.mp3"
    combined_path = os.path.join(assets_dir, combined_filename)
    combined_audio.export(combined_path, format="mp3")
    
    actual_duration = get_audio_duration(combined_path)
    result["total_duration"] = round(actual_duration, 3)
    result["combined_audio"] = f"/assets/{combined_filename}"
    
    logging.info(f"ğŸµ {video_key} combined: {combined_filename} ({actual_duration:.1f}s total)")
    
    return result


async def _build_video5_deep_dive(script: dict, assets_dir: str) -> dict:
    """
    Video 5 â€” Deep Dive Episode (YouTube Long-form).
    
    Generate separate MP3 for EACH segment with precise timing.
    Uses Azure TTS with JiMinNeural voice for analysis style.
    
    Returns:
        dict with structure:
        {
            "segments": [
                {"section": "opening", "ko": "...", "vi": "...", "audio_path": "/assets/deep_0.mp3", "duration": 15.2},
                {"section": "news", ...},
                ...
            ],
            "total_duration": 420.5,  # ~7 minutes
            "combined_audio": "/assets/v5_deep_dive.mp3",
            "timestamps": [
                {"section": "opening", "start_sec": 0, "label": "ğŸ¬ Intro"},
                {"section": "news", "start_sec": 32, "label": "ğŸ“° Tin tá»©c"},
                ...
            ]
        }
    """
    cfg = _VOICE_CFG["video_5"]
    
    if not script:
        logging.warning("âš ï¸ Video 5: No deep_dive script found â€” skipping.")
        return {"segments": [], "total_duration": 0, "combined_audio": None, "timestamps": []}
    
    result_segments = []
    combined_audio = AudioSegment.empty()
    timestamps = []
    total_duration = 0.0
    segment_idx = 0
    pause = AudioSegment.silent(duration=500)  # 0.5s between sections
    
    # Voice assignments for different parts of Deep Dive
    voice_host = AZURE_VOICE_CONFIG.get("host", "ko-KR-SunHiNeural")
    voice_news = AZURE_VOICE_CONFIG.get("news", "ko-KR-SunHiNeural")
    voice_exam = AZURE_VOICE_CONFIG.get("exam", "ko-KR-InJoonNeural")
    voice_analysis = AZURE_VOICE_CONFIG.get("analysis", "ko-KR-JiMinNeural")
    
    async def process_segment(section_name: str, ko_text: str, vi_text: str, voice: str, rate: str = "+0%"):
        """Helper to process a single segment."""
        nonlocal segment_idx, total_duration, combined_audio
        
        if not ko_text or not ko_text.strip():
            return
        
        # Generate individual audio file
        seg_filename = f"deep_{segment_idx}.mp3"
        seg_path = os.path.join(assets_dir, seg_filename)
        
        # Use Azure TTS (or fallback to edge-tts)
        duration = await generate_azure_tts_async(ko_text, voice, seg_path, rate)
        
        if duration <= 0:
            logging.warning(f"âš ï¸ Deep Dive segment {segment_idx} ({section_name}): TTS failed, skipping.")
            return
        
        relative_path = f"/assets/{seg_filename}"
        
        result_segments.append({
            "section": section_name,
            "ko": ko_text,
            "vi": vi_text,
            "audio_path": relative_path,
            "duration": round(duration, 3)
        })
        
        # Add timestamp marker
        timestamps.append({
            "section": section_name,
            "start_sec": round(total_duration, 0),
            "label": _get_section_label(section_name)
        })
        
        total_duration += duration
        
        # Build combined audio
        if os.path.exists(seg_path):
            seg_audio = AudioSegment.from_file(seg_path, format="mp3")
            combined_audio += seg_audio + pause
            total_duration += 0.5  # Account for pause
        
        logging.info(f"ğŸµ Deep Dive [{section_name}]: {seg_filename} ({duration:.2f}s)")
        segment_idx += 1
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Process each section of the Deep Dive script
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # 1. OPENING
    opening = script.get("opening", {})
    if opening:
        hook_ko = opening.get("hook_ko", "")
        intro_ko = opening.get("intro_ko", "")
        combined_opening = f"{hook_ko} {intro_ko}".strip()
        combined_vi = f"{opening.get('hook_vi', '')} {opening.get('intro_vi', '')}".strip()
        await process_segment("opening", combined_opening, combined_vi, voice_host, "-5%")
    
    # 2. NEWS
    news = script.get("news", {})
    if news:
        news_parts = []
        vi_parts = []
        for key in ["transition_ko", "content_ko", "analysis_ko"]:
            if news.get(key):
                news_parts.append(news[key])
        for key in ["transition_vi", "content_vi", "analysis_vi"]:
            if news.get(key):
                vi_parts.append(news[key])
        combined_news_ko = " ".join(news_parts)
        combined_news_vi = " ".join(vi_parts)
        await process_segment("news", combined_news_ko, combined_news_vi, voice_news)
    
    # 3. TRANSITION
    transition = script.get("transition", {})
    if transition:
        await process_segment(
            "transition",
            transition.get("bridge_ko", ""),
            transition.get("bridge_vi", ""),
            voice_host
        )
    
    # 4. EXAM
    exam = script.get("exam", {})
    if exam:
        exam_parts = []
        vi_parts = []
        for key in ["intro_ko", "question_ko", "tips_ko"]:
            if exam.get(key):
                exam_parts.append(exam[key])
        for key in ["intro_vi", "question_vi", "tips_vi"]:
            if exam.get(key):
                vi_parts.append(exam[key])
        combined_exam_ko = " ".join(exam_parts)
        combined_exam_vi = " ".join(vi_parts)
        await process_segment("exam", combined_exam_ko, combined_exam_vi, voice_exam, "-5%")
    
    # 5. ESSAY (Process each paragraph separately for better timestamps)
    essay = script.get("essay", {})
    if essay:
        # Essay intro
        intro_ko = essay.get("intro_ko", "")
        intro_vi = essay.get("intro_vi", "")
        if intro_ko:
            await process_segment("essay_intro", intro_ko, intro_vi, voice_analysis)
        
        # Essay paragraphs
        paragraphs = essay.get("paragraphs", [])
        for idx, para in enumerate(paragraphs):
            label = para.get("label", f"Para {idx+1}")
            para_ko = para.get("ko", "")
            para_vi = para.get("vi", "")
            analysis_ko = para.get("analysis_ko", "")
            analysis_vi = para.get("analysis_vi", "")
            
            # Combine paragraph content with analysis
            combined_ko = f"{para_ko} {analysis_ko}".strip()
            combined_vi = f"{para_vi} {analysis_vi}".strip()
            
            if combined_ko:
                await process_segment(f"essay_{label}", combined_ko, combined_vi, voice_analysis)
    
    # 6. VOCAB
    vocab = script.get("vocab", {})
    if vocab:
        # Vocab intro
        vocab_intro = vocab.get("intro_ko", "")
        vocab_intro_vi = vocab.get("intro_vi", "")
        if vocab_intro:
            await process_segment("vocab_intro", vocab_intro, vocab_intro_vi, voice_analysis)
        
        # Vocab items
        vocab_items = vocab.get("items", [])
        for item in vocab_items:
            word = item.get("word", "")
            explanation_ko = item.get("explanation_ko", "")
            example_ko = item.get("example_ko", "")
            meaning_vi = item.get("meaning_vi", "")
            example_vi = item.get("example_vi", "")
            
            combined_ko = f"{word}. {explanation_ko} {example_ko}".strip()
            combined_vi = f"{meaning_vi} {example_vi}".strip()
            
            if combined_ko:
                await process_segment(f"vocab_{word}", combined_ko, combined_vi, voice_analysis)
        
        # Grammar items
        grammar_items = vocab.get("grammar_items", [])
        for item in grammar_items:
            point = item.get("point", "")
            explanation_ko = item.get("explanation_ko", "")
            example_ko = item.get("example_ko", "")
            meaning_vi = item.get("meaning_vi", "")
            example_vi = item.get("example_vi", "")
            
            combined_ko = f"{point}. {explanation_ko} {example_ko}".strip()
            combined_vi = f"{meaning_vi} {example_vi}".strip()
            
            if combined_ko:
                await process_segment(f"grammar_{point}", combined_ko, combined_vi, voice_analysis)
    
    # 7. CLOSING
    closing = script.get("closing", {})
    if closing:
        closing_parts = []
        vi_parts = []
        for key in ["summary_ko", "cta_ko", "outro_ko"]:
            if closing.get(key):
                closing_parts.append(closing[key])
        for key in ["summary_vi", "cta_vi", "outro_vi"]:
            if closing.get(key):
                vi_parts.append(closing[key])
        combined_closing_ko = " ".join(closing_parts)
        combined_closing_vi = " ".join(vi_parts)
        await process_segment("closing", combined_closing_ko, combined_closing_vi, voice_host)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Export combined audio
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    combined_path = os.path.join(assets_dir, "v5_deep_dive.mp3")
    if len(combined_audio) > 0:
        combined_audio.export(combined_path, format="mp3")
        logging.info(f"ğŸµ Video 5 combined: {combined_path} ({total_duration:.1f}s = {total_duration/60:.1f}min total)")
    
    return {
        "segments": result_segments,
        "total_duration": round(total_duration, 3),
        "combined_audio": "/assets/v5_deep_dive.mp3",
        "timestamps": timestamps
    }


def _get_section_label(section: str) -> str:
    """Get human-readable label for timestamp."""
    labels = {
        "opening": "ğŸ¬ Intro",
        "news": "ğŸ“° Tin tá»©c",
        "transition": "ğŸ”„ Chuyá»ƒn tiáº¿p",
        "exam": "ğŸ“ Äá» thi TOPIK 54",
        "essay_intro": "âœï¸ VÄƒn máº«u",
        "vocab_intro": "ğŸ“š Tá»« vá»±ng & Ngá»¯ phÃ¡p",
        "closing": "ğŸ‘‹ Káº¿t thÃºc",
    }
    # Check for partial matches
    for key, label in labels.items():
        if section.startswith(key):
            return label
    return section


async def generate_tiktok_assets(phase3_json: dict, assets_dir: str, phase4_json: dict = None) -> dict:
    """
    Entry-point for audio asset generation with SEGMENT-LEVEL timing.

    Input:  phase3_json â€” data from Phase 3 (contains tiktok_script)
    
    Output: dict with structure:
        {
            "audio_paths": {
                "video_1_news": "/assets/v1_news.mp3",
                "video_2_outline": "/assets/v2_outline.mp3",
                ...
            },
            "audio_data": {
                "video_1_news": {
                    "segments": [{...}],
                    "total_duration": 15.5,
                    ...
                },
                ...
            }
        }
    
    The audio_data contains precise timing info for each segment/part.
    """
    logging.info("ğŸ¤ Báº¯t Ä‘áº§u generate_tiktok_assets â€” Segment-based audio generation...")

    tiktok = phase3_json.get("tiktok_script", {})
    if not tiktok:
        logging.error("âŒ tiktok_script khÃ´ng tÃ¬m tháº¥y trong Phase 3 output.")
        return {"audio_paths": {}, "audio_data": {}}

    os.makedirs(assets_dir, exist_ok=True)

    audio_paths = {}   # Backward compatible: {video_key: combined_audio_path}
    audio_data = {}    # NEW: Detailed timing data per video

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Video 1: News Healing â€” Per-segment audio
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    v1_data = await _build_video1_news(tiktok.get("video_1_news", {}), assets_dir)
    audio_data["video_1_news"] = v1_data
    if v1_data.get("combined_audio"):
        audio_paths["video_1_news"] = os.path.join(assets_dir, "v1_news.mp3")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Video 2: Writing Coach â€” Per-part audio
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    v2_data = await _build_video2_outline(tiktok.get("video_2_outline", {}), assets_dir)
    audio_data["video_2_outline"] = v2_data
    if v2_data.get("combined_audio"):
        audio_paths["video_2_outline"] = os.path.join(assets_dir, "v2_outline.mp3")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Video 3: Vocab Quiz â€” Question + Answer split
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    v3_data = await _build_quiz_audio(tiktok.get("video_3_vocab_quiz", {}), assets_dir, "video_3")
    audio_data["video_3_vocab_quiz"] = v3_data
    if v3_data.get("combined_audio"):
        audio_paths["video_3_vocab_quiz"] = os.path.join(assets_dir, "v3_vocab_quiz.mp3")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Video 4: Grammar Quiz â€” Question + Answer split
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    v4_data = await _build_quiz_audio(tiktok.get("video_4_grammar_quiz", {}), assets_dir, "video_4")
    audio_data["video_4_grammar_quiz"] = v4_data
    if v4_data.get("combined_audio"):
        audio_paths["video_4_grammar_quiz"] = os.path.join(assets_dir, "v4_grammar_quiz.mp3")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Video 5: Deep Dive Episode â€” Per-segment audio (YouTube long-form)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if phase4_json and phase4_json.get("video_5_deep_dive"):
        v5_data = await _build_video5_deep_dive(phase4_json["video_5_deep_dive"], assets_dir)
        audio_data["video_5_deep_dive"] = v5_data
        if v5_data.get("combined_audio"):
            audio_paths["video_5_deep_dive"] = os.path.join(assets_dir, "v5_deep_dive.mp3")
    else:
        logging.info("â„¹ï¸ Video 5 (Deep Dive) skipped â€” no Phase 4 data provided.")

    logging.info("âœ… generate_tiktok_assets hoÃ n thÃ nh â€” Segment-based audio vá»›i timing chÃ­nh xÃ¡c.")
    
    return {
        "audio_paths": audio_paths,
        "audio_data": audio_data
    }


# ==============================================================================
# 4. WORD DOCUMENT CREATION  (Giá»¯ nguyÃªn logic, cáº­p nháº­t data source)
# ==============================================================================

def create_professional_docx(data_p1: dict, data_p2: dict, data_p3: dict, source_url: str) -> str | None:
    """
    Táº¡o file Word chuyÃªn nghiá»‡p tá»« dá»¯ liá»‡u 3 phases.
    Dá»¯ liá»‡u vocab/grammar láº¥y tá»« word_doc_data (Phase 3 má»›i).
    """
    logging.info("ğŸ“ Äang táº¡o file Word...")

    # --- Xá»­ lÃ½ tÃªn file ---
    raw_title = data_p1.get('topic_korean', 'Topic_Moi')
    safe_title = re.sub(r'[\\/*?:"<>|]', "", raw_title).replace(" ", "_")

    output_dir = os.environ.get('OUTPUT_DIR', 'public')
    os.makedirs(output_dir, exist_ok=True)
    filename = os.path.join(output_dir, f"TOPIK_WRITING_{safe_title[:30]}.docx")

    try:
        doc = Document()

        # Default font
        style      = doc.styles['Normal']
        style.font.name = 'Times New Roman'
        style.font.size = Pt(11)

        # ===== HEADER =====
        header_text = f"TOPIK II CÃ‚U 54 - {sanitize_text(raw_title)}"
        header = doc.add_heading(header_text, 0)
        header.alignment = WD_ALIGN_PARAGRAPH.CENTER

        doc.add_paragraph(f"Nguá»“n tin: {source_url}").italic = True
        doc.add_paragraph(f"NgÃ y táº¡o: {datetime.now().strftime('%d/%m/%Y')}")
        doc.add_paragraph("-" * 60)

        # ===== 1. Äá»€ BÃ€I =====
        doc.add_heading('1. Äá»€ BÃ€I (QUESTION)', level=1)
        table = doc.add_table(rows=1, cols=1)
        table.style = 'Table Grid'
        cell = table.cell(0, 0)

        korean_question = data_p1.get('question_full_text', '')
        p_kr = cell.add_paragraph(sanitize_text(korean_question))
        p_kr.paragraph_format.space_after = Pt(12)

        doc.add_paragraph().add_run("\n")

        # ===== 2. BÃ€I VÄ‚N MáºªU =====
        doc.add_heading('2. BÃ€I VÄ‚N MáºªU (MODEL ESSAY)', level=1)

        essay_kr = data_p2.get('essay', '')
        doc.add_heading('ğŸ‡°ğŸ‡· Tiáº¿ng HÃ n:', level=3)

        for para in essay_kr.split('\n'):
            if para.strip():
                p = doc.add_paragraph(sanitize_text(para.strip()))
                p.paragraph_format.first_line_indent = Pt(20)
                p.paragraph_format.space_after = Pt(6)

        doc.add_paragraph().add_run("\n")

        # ===== 3. Tá»ª Vá»°NG & NGá»® PHÃP (tá»« word_doc_data) =====
        doc.add_heading('3. Tá»ª Vá»°NG (VOCABULARY)', level=1)

        word_doc = data_p3.get('word_doc_data', {})
        vocab_list = word_doc.get('vocab_list', [])

        if not vocab_list:
            doc.add_paragraph("(KhÃ´ng cÃ³ dá»¯ liá»‡u tá»« vá»±ng)")
        else:
            for item in vocab_list:
                word       = item.get('word', 'N/A')
                meaning_vi = item.get('meaning_vi', '')
                example    = item.get('example', '')

                p = doc.add_paragraph(style='List Bullet')

                # Tá»« vá»±ng â€” in Ä‘áº­m, xanh
                run_word = p.add_run(sanitize_text(word))
                run_word.bold = True
                run_word.font.color.rgb = RGBColor(0, 50, 150)

                if meaning_vi:
                    p.add_run(f" : {sanitize_text(meaning_vi)}")

                if example:
                    run_ex = p.add_run(f"\n   â”” ğŸ’¡ {sanitize_text(example)}")
                    run_ex.font.size = Pt(10)
                    run_ex.font.color.rgb = RGBColor(100, 100, 100)

        # --- Ngá»¯ phÃ¡p ---
        doc.add_paragraph().add_run("\n")
        doc.add_heading('4. NGá»® PHÃP (GRAMMAR)', level=1)

        grammar_list = word_doc.get('grammar_list', [])

        if not grammar_list:
            doc.add_paragraph("(KhÃ´ng cÃ³ dá»¯ liá»‡u ngá»¯ phÃ¡p)")
        else:
            for item in grammar_list:
                point      = item.get('point', 'N/A')
                meaning_vi = item.get('meaning_vi', '')
                example    = item.get('example', '')

                p = doc.add_paragraph(style='List Bullet')

                run_point = p.add_run(sanitize_text(point))
                run_point.bold = True
                run_point.font.color.rgb = RGBColor(0, 100, 50)

                if meaning_vi:
                    p.add_run(f" : {sanitize_text(meaning_vi)}")

                if example:
                    run_ex = p.add_run(f"\n   â”” ğŸ’¡ {sanitize_text(example)}")
                    run_ex.font.size = Pt(10)
                    run_ex.font.color.rgb = RGBColor(100, 100, 100)

        # --- Cloze Test ---
        doc.add_paragraph().add_run("\n")
        doc.add_heading('5. CLOZE TEST (ÄIá»€N CHá»– TRá»NG)', level=1)

        cloze = word_doc.get('cloze_test', {})
        if cloze:
            doc.add_paragraph(f"ğŸ“ CÃ¢u há»i: {sanitize_text(cloze.get('question', ''))}")
            doc.add_paragraph(f"âœ… ÄÃ¡p Ã¡n:  {sanitize_text(cloze.get('answer', ''))}")
            doc.add_paragraph(f"ğŸ’¡ Gá»£i Ã½:   {sanitize_text(cloze.get('hint_vi', ''))}")

        # ===== LÆ¯U FILE =====
        try:
            doc.save(filename)
            logging.info(f"âœ… ÄÃ£ táº¡o file Word: {filename}")
            return filename
        except PermissionError:
            new_filename = filename.replace(".docx", f"_{int(time.time())}.docx")
            logging.warning(f"âš ï¸  File Ä‘ang má»Ÿ. LÆ°u sang {new_filename}...")
            doc.save(new_filename)
            return new_filename

    except Exception as e:
        logging.error(f"âŒ Lá»—i táº¡o Word: {e}")
        traceback.print_exc()
        return None


# ==============================================================================
# 5. YOUTUBE METADATA GENERATION  â€”  Auto-generate timestamps, title, hashtags
# ==============================================================================

def generate_youtube_description(json_data: dict, output_path: str = None) -> str:
    """
    Generate YouTube description with auto-calculated timestamps.
    
    Args:
        json_data: Final data JSON containing audio_data with timestamps
        output_path: Path to save youtube_info.txt (optional)
        
    Returns:
        Generated description text
    """
    logging.info("ğŸ“ Äang táº¡o YouTube metadata...")
    
    # Extract data
    meta = json_data.get("meta", {})
    phase1 = json_data.get("phase1", {})
    phase4 = json_data.get("phase4", {})
    audio_data = json_data.get("audio_data", {})
    
    # Get video 5 timestamps
    v5_data = audio_data.get("video_5_deep_dive", {})
    timestamps = v5_data.get("timestamps", [])
    total_duration = v5_data.get("total_duration", 0)
    
    # Get metadata from Phase 4
    deep_dive_meta = {}
    if phase4 and phase4.get("video_5_deep_dive"):
        deep_dive_meta = phase4["video_5_deep_dive"].get("meta", {})
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # BUILD YOUTUBE DESCRIPTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    lines = []
    
    # Title
    title_vi = deep_dive_meta.get("title_vi", meta.get("topic_title_vi", "TOPIK ì“°ê¸° 54 - Deep Dive"))
    title_ko = deep_dive_meta.get("title_ko", phase1.get("topic_korean", ""))
    
    lines.append("=" * 60)
    lines.append("ğŸ“º YOUTUBE VIDEO METADATA")
    lines.append("=" * 60)
    lines.append("")
    lines.append(f"ğŸ¬ TITLE (VI): {title_vi}")
    lines.append(f"ğŸ¬ TITLE (KO): {title_ko}")
    lines.append("")
    
    # Duration
    duration_min = total_duration / 60
    lines.append(f"â±ï¸ DURATION: {_format_timestamp(total_duration)} ({duration_min:.1f} phÃºt)")
    lines.append("")
    
    # Timestamps
    lines.append("ğŸ“Œ TIMESTAMPS:")
    lines.append("-" * 40)
    
    if timestamps:
        for ts in timestamps:
            start_sec = ts.get("start_sec", 0)
            label = ts.get("label", ts.get("section", ""))
            timestamp_str = _format_timestamp(start_sec)
            lines.append(f"{timestamp_str} - {label}")
    else:
        # Fallback: Generate estimated timestamps
        lines.append("00:00 - ğŸ¬ Intro")
        lines.append("00:30 - ğŸ“° Tin tá»©c & PhÃ¢n tÃ­ch")
        lines.append("02:00 - ğŸ“ Äá» thi TOPIK 54")
        lines.append("03:30 - âœï¸ VÄƒn máº«u & PhÃ¢n tÃ­ch")
        lines.append("06:00 - ğŸ“š Tá»« vá»±ng & Ngá»¯ phÃ¡p")
        lines.append("08:00 - ğŸ‘‹ Káº¿t thÃºc")
    
    lines.append("")
    
    # Description
    lines.append("ğŸ“„ DESCRIPTION:")
    lines.append("-" * 40)
    
    description = deep_dive_meta.get("description_vi", "")
    if description:
        lines.append(description)
    else:
        # Generate default description
        topic = meta.get("topic_title_vi", "")
        lines.append(f"ğŸ“ DAILY KOREAN - ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆ | PhÃ¢n tÃ­ch chuyÃªn sÃ¢u Ä‘á» thi TOPIK II CÃ¢u 54")
        lines.append(f"")
        lines.append(f"Trong video nÃ y, chÃºng ta sáº½ cÃ¹ng nhau:")
        lines.append(f"âœ… PhÃ¢n tÃ­ch xu hÆ°á»›ng tin tá»©c xÃ£ há»™i HÃ n Quá»‘c")
        lines.append(f"âœ… LÃ m quen vá»›i dáº¡ng Ä‘á» TOPIK 54 (600-700 chá»¯)")
        lines.append(f"âœ… Há»c cÃ¡ch viáº¿t bÃ i vÄƒn máº«u Ä‘áº¡t Ä‘iá»ƒm tá»‘i Ä‘a")
        lines.append(f"âœ… Náº¯m vá»¯ng tá»« vá»±ng vÃ  ngá»¯ phÃ¡p quan trá»ng")
        lines.append(f"")
        lines.append(f"ğŸ“š Chá»§ Ä‘á» hÃ´m nay: {topic}")
    
    lines.append("")
    
    # Hashtags
    lines.append("ğŸ·ï¸ HASHTAGS:")
    lines.append("-" * 40)
    
    hashtags = deep_dive_meta.get("hashtags", [])
    if not hashtags:
        hashtags = [
            "#TOPIK", "#TOPIKwriting", "#í† í”½ì“°ê¸°", "#í† í”½54",
            "#KoreanLearning", "#LearnKorean", "#Há»cTiáº¿ngHÃ n",
            "#TOPIKII", "#KoreanTest", "#í† í”½ì‹œí—˜",
            "#DailyKorean", "#ë°ì¼ë¦¬ì½”ë¦¬ì•ˆ", "#VietnamKorea"
        ]
    
    lines.append(" ".join(hashtags))
    lines.append("")
    
    # SEO Keywords
    lines.append("ğŸ” SEO KEYWORDS:")
    lines.append("-" * 40)
    lines.append("TOPIK ì“°ê¸° 54, TOPIK writing, í† í”½ ì‘ë¬¸, há»c tiáº¿ng HÃ n, Korean essay, máº«u bÃ i viáº¿t TOPIK")
    lines.append("")
    
    # Social Links (placeholder)
    lines.append("ğŸ”— LINKS:")
    lines.append("-" * 40)
    lines.append("ğŸ“± TikTok: @deep_dive_korean")
    lines.append("ğŸ“¸ Instagram: @deep_dive_korean")
    lines.append("ğŸ’¬ Discord: [Link cá»™ng Ä‘á»“ng]")
    lines.append("")
    
    lines.append("=" * 60)
    
    # Join all lines
    description_text = "\n".join(lines)
    
    # Save to file if path provided
    if output_path:
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(description_text)
            logging.info(f"âœ… ÄÃ£ lÆ°u YouTube metadata: {output_path}")
        except Exception as e:
            logging.error(f"âŒ Lá»—i lÆ°u YouTube metadata: {e}")
    
    return description_text


def _format_timestamp(seconds: float) -> str:
    """Format seconds as MM:SS or HH:MM:SS timestamp."""
    seconds = int(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


# ==============================================================================
# 6. REMOTION RENDER  â€”  Há»— trá»£ CompositionID tÃ¹y chá»n + Error Handling
# ==============================================================================

def render_single_video(composition_id: str, json_path: str, output_path: str) -> bool:
    """
    Render 1 video vá»›i CompositionID cá»¥ thá»ƒ.
    Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cho json_path vÃ  output_path.
    """
    abs_json   = os.path.abspath(json_path)
    abs_output = os.path.abspath(output_path)

    if not os.path.exists(abs_json):
        logging.error(f"âŒ [{composition_id}] File data khÃ´ng tá»“n táº¡i: {abs_json}")
        return False

    logging.info(f"ğŸ¥ Render [{composition_id}] â†’ {os.path.basename(abs_output)}")

    # TrÃªn Windows, cáº§n sá»­ dá»¥ng shell=True Ä‘á»ƒ tÃ¬m npx trong PATH
    # TrÃªn Linux, shell=False hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n (trÃ¡nh TTY issues)
    import platform
    is_windows = platform.system() == "Windows"
    
    cmd = [
        "npx", "remotion", "render",
        composition_id,             # TÃªn Composition (khÃ¡c nhau cho má»—i video)
        abs_output,                 # Output path (tuyá»‡t Ä‘á»‘i)
        "--props", abs_json,        # Props JSON (tuyá»‡t Ä‘á»‘i)
        "--concurrency=1",          # Concurrency=1 Ä‘á»ƒ trÃ¡nh browser crash
        "--gl=angle" if is_windows else "--gl=swangle",  # swangle tá»‘t hÆ¡n trÃªn Linux headless
        "--log=info"
    ]

    try:
        # shell=True cáº§n thiáº¿t trÃªn Windows Ä‘á»ƒ tÃ¬m npx trong PATH
        # shell=False trÃªn Linux Ä‘á»ƒ trÃ¡nh TTY/interactive shell issues
        subprocess.run(
            cmd, 
            check=True, 
            cwd="topik-video", 
            capture_output=False, 
            shell=is_windows,
            stdin=subprocess.DEVNULL  # Prevent interactive prompts
        )

        if os.path.exists(abs_output):
            file_size_mb = os.path.getsize(abs_output) / (1024 * 1024)
            logging.info(f"âœ… [{composition_id}] OK â€” {file_size_mb:.1f} MB")
            return True
        else:
            logging.error(f"âŒ [{composition_id}] Render done nhÆ°ng file khÃ´ng tháº¥y.")
            return False

    except subprocess.CalledProcessError as e:
        logging.error(f"âŒ [{composition_id}] Remotion lá»—i (Exit {e.returncode}). Xem log bÃªn trÃªn.")
        return False
    except Exception as e:
        logging.error(f"âŒ [{composition_id}] Lá»—i ngoáº¡i lá»‡: {e}")
        return False


def render_all_videos(json_path: str, include_deep_dive: bool = True) -> list[str]:
    """
    Render loop: cháº¡y 5 láº§n liÃªn tiáº¿p, má»—i láº§n vá»›i CompositionID khÃ¡c nhau.
    
    Args:
        json_path: Path to the final_data.json file
        include_deep_dive: Whether to include Video 5 (Deep Dive)
        
    Returns: danh sÃ¡ch paths cá»§a cÃ¡c video Ä‘Ã£ render thÃ nh cÃ´ng.
    
    Error Handling: Má»—i video Ä‘Æ°á»£c wrap trong try/except riÃªng Ä‘á»ƒ Ä‘áº£m báº£o
    náº¿u 1 video lá»—i, cÃ¡c video khÃ¡c váº«n tiáº¿p tá»¥c render.
    """
    logging.info("=" * 60)
    logging.info("ğŸ¬ Báº®T Äáº¦U RENDER LOOP â€” 5 VIDEO (4 TikTok + 1 YouTube Deep Dive)")
    logging.info("=" * 60)

    timestamp   = int(time.time())
    rendered    = []                    # Paths video thÃ nh cÃ´ng
    failed      = []                    # Composition IDs that failed
    
    manifest_to_use = VIDEO_MANIFEST if include_deep_dive else VIDEO_MANIFEST[:4]

    for entry in manifest_to_use:
        composition = entry["composition"]    # e.g. "TikTok_NewsHealing"
        prefix      = entry["prefix"]         # e.g. "V1_News"

        video_filename = f"{prefix}_{timestamp}.mp4"
        video_path     = os.path.join("topik-video", "public", video_filename)

        try:
            success = render_single_video(composition, json_path, video_path)

            if success:
                rendered.append(video_path)
                logging.info(f"âœ… [{composition}] Render thÃ nh cÃ´ng.")
            else:
                failed.append(composition)
                logging.warning(f"âš ï¸ [{composition}] tháº¥t báº¡i â€” tiáº¿p tá»¥c cÃ¡c video cÃ²n láº¡i.")
                
        except Exception as e:
            failed.append(composition)
            logging.error(f"âŒ [{composition}] Exception during render: {e}")
            traceback.print_exc()
            logging.info("   â†’ Tiáº¿p tá»¥c vá»›i video tiáº¿p theo...")
            continue

    # Summary
    total = len(manifest_to_use)
    success_count = len(rendered)
    fail_count = len(failed)
    
    logging.info("=" * 60)
    logging.info(f"ğŸ¬ Render loop hoÃ n thÃ nh: {success_count}/{total} video OK")
    if failed:
        logging.warning(f"   âŒ Failed compositions: {', '.join(failed)}")
    logging.info("=" * 60)
    
    return rendered


# ==============================================================================
# 7. MAIN â€” Orchestrator (Updated for 5 videos + YouTube metadata)
# ==============================================================================

def main():
    logging.info("=" * 60)
    logging.info("ğŸš€ DAILY KOREAN v3.0 â€” ë°ì¼ë¦¬ ì½”ë¦¬ì•ˆ Content Automation")
    logging.info("=" * 60)

    # Biáº¿n Ä‘á»ƒ upload sau cÃ¹ng
    docx_path    = None
    youtube_info_path = None
    rendered_videos = []

    # ------------------------------------------------------------------
    # PHASE 1: Crawl News + Ra Ä‘á»
    # ------------------------------------------------------------------
    url_rss, source_name = get_latest_editorial_rss()
    if not url_rss:
        logging.error("âŒ KhÃ´ng tÃ¬m Ä‘Æ°á»£c bÃ i bÃ¡o tá»« RSS. Dá»«ng.")
        return

    content = extract_content(url_rss)
    if not content:
        logging.error("âŒ KhÃ´ng táº£i Ä‘Æ°á»£c ná»™i dung bÃ i bÃ¡o. Dá»«ng.")
        return

    data_p1 = run_phase_1(content['text'])
    if not data_p1:
        logging.error("âŒ Phase 1 tháº¥t báº¡i. Dá»«ng.")
        return

    # ------------------------------------------------------------------
    # PHASE 2: VÄƒn máº«u + PhÃ¢n tÃ­ch
    # ------------------------------------------------------------------
    data_p2 = run_phase_2(data_p1)
    if not data_p2:
        logging.error("âŒ Phase 2 tháº¥t báº¡i. Dá»«ng.")
        return

    # ------------------------------------------------------------------
    # Táº£i video ná»n (song song vá»›i Phase 3 â€” khÃ´ng block)
    # ------------------------------------------------------------------
    keyword = data_p1.get('video_keyword', 'study')
    bg_download_result = download_background_video(keyword, os.path.join(ASSETS_DIR, "background_loop.mp4"))
    
    # Extract video duration from download result
    video_bg_duration = 0.0
    if isinstance(bg_download_result, dict):
        video_bg_duration = bg_download_result.get("duration", 0.0)
    elif VIDEO_BG_DURATION_CACHE > 0:
        video_bg_duration = VIDEO_BG_DURATION_CACHE

    # ------------------------------------------------------------------
    # PHASE 3: Multi-channel editor â†’ JSON 4 video + Word data
    # ------------------------------------------------------------------
    data_p3 = run_phase_3(data_p1, data_p2)
    if not data_p3:
        logging.error("âŒ Phase 3 tháº¥t báº¡i. Dá»«ng.")
        return

    # ------------------------------------------------------------------
    # PHASE 4: Deep Dive Episode â†’ JSON video 5 (YouTube long-form)
    # ------------------------------------------------------------------
    data_p4 = run_phase_4(data_p1, data_p2, data_p3)
    if not data_p4:
        logging.warning("âš ï¸ Phase 4 tháº¥t báº¡i â€” Video 5 sáº½ bá»‹ bá» qua.")
        include_deep_dive = False
    else:
        include_deep_dive = True
        logging.info("âœ… Phase 4 hoÃ n thÃ nh â€” Deep Dive script OK")

    # ------------------------------------------------------------------
    # GENERATE TIKTOK AUDIO ASSETS â€” Segment-based with timing (5 videos)
    # ------------------------------------------------------------------
    audio_result = asyncio.run(generate_tiktok_assets(data_p3, ASSETS_DIR, data_p4 if include_deep_dive else None))
    if not audio_result or not audio_result.get("audio_paths"):
        logging.error("âŒ KhÃ´ng táº¡o Ä‘Æ°á»£c audio assets. Dá»«ng.")
        return
    
    audio_paths = audio_result["audio_paths"]
    audio_data = audio_result["audio_data"]

    # ------------------------------------------------------------------
    # Táº O FILE WORD
    # ------------------------------------------------------------------
    docx_path = create_professional_docx(data_p1, data_p2, data_p3, url_rss)

    # ------------------------------------------------------------------
    # LÆ¯U final_data.json  â€” dá»¯ liá»‡u tá»•ng há»£p cho Remotion
    # ------------------------------------------------------------------
    # Copy background video sang vá»‹ trÃ­ Remotion expect
    bg_src  = os.path.join(ASSETS_DIR, "background_loop.mp4")
    bg_dest = os.path.join("topik-video", "public", "assets", "background.mp4")
    if os.path.exists(bg_src):
        os.makedirs(os.path.dirname(bg_dest), exist_ok=True)
        shutil.copy(bg_src, bg_dest)

    # XÃ¢y dá»±ng payload JSON cho Remotion
    # Audio paths chuyá»ƒn vá» relative (Remotion serve tá»« /public)
    relative_audio_paths = {
        key: f"/assets/{os.path.basename(path)}"
        for key, path in audio_paths.items()
    }

    # Merge audio_data timing into tiktok_script for Remotion
    tiktok_script = data_p3.get("tiktok_script", {})
    
    # Enrich video_1_news with segment timing
    if "video_1_news" in audio_data and audio_data["video_1_news"].get("segments"):
        tiktok_script["video_1_news"]["segments"] = audio_data["video_1_news"]["segments"]
        tiktok_script["video_1_news"]["total_duration"] = audio_data["video_1_news"]["total_duration"]
    
    # Enrich video_2_outline with part timing
    if "video_2_outline" in audio_data and audio_data["video_2_outline"].get("parts"):
        tiktok_script["video_2_outline"]["parts"] = audio_data["video_2_outline"]["parts"]
        tiktok_script["video_2_outline"]["total_duration"] = audio_data["video_2_outline"]["total_duration"]
    
    # Enrich quiz videos with split audio timing
    for quiz_key in ["video_3_vocab_quiz", "video_4_grammar_quiz"]:
        if quiz_key in audio_data:
            tiktok_script[quiz_key]["audio_timing"] = {
                "question": audio_data[quiz_key].get("question_audio"),
                "answer": audio_data[quiz_key].get("answer_audio"),
                "silence_duration": audio_data[quiz_key].get("silence_duration", 4.0),
                "total_duration": audio_data[quiz_key].get("total_duration", 0)
            }

    # Build final_data JSON
    final_data = {
        "meta":           data_p3.get("meta", {}),
        "phase1":         data_p1,
        "phase2":         data_p2,
        "phase4":         data_p4 if include_deep_dive else {},   # Deep Dive data
        "tiktok_script":  tiktok_script,              # Enriched with timing
        "word_doc_data":  data_p3.get("word_doc_data", {}),
        "audio_paths":    relative_audio_paths,       # Relative paths cho Remotion
        "audio_data":     audio_data,                 # Full timing data
        "video_bg":       "/assets/background.mp4",
        "video_bg_duration": video_bg_duration,       # NEW: Actual video duration in seconds
    }
    
    # Log video background info
    if video_bg_duration > 0:
        logging.info(f"ğŸ“¹ Video background duration: {video_bg_duration:.2f}s")
    else:
        logging.warning("âš ï¸ Video background duration unknown, Remotion will use default fallback")
    
    # Add video_5_deep_dive to tiktok_script if available
    if include_deep_dive and data_p4.get("video_5_deep_dive"):
        final_data["tiktok_script"]["video_5_deep_dive"] = data_p4["video_5_deep_dive"]
        # Enrich with audio timing data
        if "video_5_deep_dive" in audio_data:
            final_data["tiktok_script"]["video_5_deep_dive"]["segments"] = audio_data["video_5_deep_dive"].get("segments", [])
            final_data["tiktok_script"]["video_5_deep_dive"]["total_duration"] = audio_data["video_5_deep_dive"].get("total_duration", 0)
            final_data["tiktok_script"]["video_5_deep_dive"]["timestamps"] = audio_data["video_5_deep_dive"].get("timestamps", [])

    json_path = os.path.join(OUTPUT_DIR, "final_data.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    logging.info(f"ğŸ’¾ ÄÃ£ lÆ°u: {json_path}")

    # ------------------------------------------------------------------
    # GENERATE YOUTUBE METADATA (Timestamps, Title, Hashtags)
    # ------------------------------------------------------------------
    if include_deep_dive:
        youtube_info_path = os.path.join(OUTPUT_DIR, "youtube_info.txt")
        generate_youtube_description(final_data, youtube_info_path)
    
    # ------------------------------------------------------------------
    # RENDER LOOP â€” 5 video (4 TikTok + 1 YouTube Deep Dive)
    # ------------------------------------------------------------------
    rendered_videos = render_all_videos(json_path, include_deep_dive=include_deep_dive)

    # ------------------------------------------------------------------
    # UPLOAD LÃŠN GOOGLE DRIVE
    # ------------------------------------------------------------------
    DRIVE_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID")
    ENABLE_YOUTUBE_UPLOAD = os.getenv("ENABLE_YOUTUBE_UPLOAD", "false").lower() == "true"
    YOUTUBE_PRIVACY = os.getenv("YOUTUBE_PRIVACY", "unlisted")  # public, unlisted, private
    YOUTUBE_PLAYLIST_ID = os.getenv("YOUTUBE_PLAYLIST_ID", "")

    # --- Google Drive Upload ---
    if DRIVE_FOLDER_ID:
        logging.info("-" * 60)
        logging.info("â˜ï¸  Báº¯t Ä‘áº§u Upload lÃªn Google Drive...")

        # --- Upload Word ---
        if docx_path and os.path.exists(docx_path):
            upload_to_drive(docx_path, DRIVE_FOLDER_ID)
        else:
            logging.warning("âš ï¸  KhÃ´ng tÃ¬m tháº¥y file Word Ä‘á»ƒ upload.")

        # --- Upload YouTube metadata (if Deep Dive was generated) ---
        if youtube_info_path and os.path.exists(youtube_info_path):
            logging.info("ğŸ“ Upload YouTube metadata...")
            upload_to_drive(youtube_info_path, DRIVE_FOLDER_ID)
        
        # --- Upload cÃ¡c video Ä‘Ã£ render thÃ nh cÃ´ng ---
        if rendered_videos:
            for vid_path in rendered_videos:
                if os.path.exists(vid_path) and os.path.getsize(vid_path) > 1024 * 1024:
                    logging.info(f"ğŸ¬ Upload Drive: {os.path.basename(vid_path)}")
                    file_id = upload_to_drive(vid_path, DRIVE_FOLDER_ID)
                    if file_id:
                        logging.info(f"   âœ… Drive Upload OK â€” ID: {file_id}")
                    else:
                        logging.error(f"   âŒ Drive Upload tháº¥t báº¡i: {vid_path}")
                else:
                    logging.warning(f"âš ï¸  Bá» qua file nhá» hoáº·c khÃ´ng tá»“n táº¡i: {vid_path}")
        else:
            # Fallback: quÃ©t toÃ n thÆ° má»¥c nhÆ° logic gá»‘c (an toÃ n)
            logging.warning("âš ï¸  Render loop khÃ´ng táº¡o video â€” thá»­ quÃ©t thÆ° má»¥c...")
            for root, _dirs, files in os.walk("."):
                for fname in files:
                    if fname.endswith(".mp4") and "background" not in fname:
                        full = os.path.join(root, fname)
                        if os.path.getsize(full) > 1024 * 1024:
                            logging.info(f"ğŸ¬ TÃ¬m tháº¥y video rogue: {full}")
                            upload_to_drive(full, DRIVE_FOLDER_ID)
    else:
        logging.warning("âš ï¸ Thiáº¿u DRIVE_FOLDER_ID â€” bá» qua Drive upload.")

    # ------------------------------------------------------------------
    # UPLOAD LÃŠN YOUTUBE (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    youtube_results = []
    
    if ENABLE_YOUTUBE_UPLOAD and YOUTUBE_UPLOAD_AVAILABLE and rendered_videos:
        logging.info("-" * 60)
        logging.info("ğŸ“º Báº¯t Ä‘áº§u Upload lÃªn YouTube...")
        
        try:
            youtube_uploader = YouTubeUploader()
            if youtube_uploader.authenticate():
                # Get channel info
                channel_info = youtube_uploader.get_channel_info()
                if channel_info:
                    logging.info(f"   ğŸ“º Channel: {channel_info['title']}")
                
                # PhÃ¢n loáº¡i video
                tiktok_videos = [v for v in rendered_videos if "V5_DeepDive" not in v]
                deep_dive_videos = [v for v in rendered_videos if "V5_DeepDive" in v]
                
                # Upload TikTok videos as Shorts
                if tiktok_videos:
                    logging.info(f"   ğŸ¬ Uploading {len(tiktok_videos)} TikTok Shorts...")
                    shorts_results = upload_tiktok_to_youtube(
                        video_paths=tiktok_videos,
                        video_data=final_data,
                        uploader=youtube_uploader,
                        playlist_id=YOUTUBE_PLAYLIST_ID if YOUTUBE_PLAYLIST_ID else None,
                        privacy=YOUTUBE_PRIVACY
                    )
                    youtube_results.extend(shorts_results)
                    
                    successful = [r for r in shorts_results if r.get("success")]
                    logging.info(f"   âœ… Shorts: {len(successful)}/{len(tiktok_videos)} uploaded")
                
                # Upload Deep Dive video (long-form)
                if deep_dive_videos:
                    logging.info("   ğŸ¥ Uploading Deep Dive video...")
                    for deep_video in deep_dive_videos:
                        dd_result = upload_deep_dive_to_youtube(
                            video_path=deep_video,
                            video_data=final_data,
                            youtube_info_path=youtube_info_path,
                            uploader=youtube_uploader,
                            privacy=YOUTUBE_PRIVACY
                        )
                        youtube_results.append(dd_result)
                        
                        if dd_result.get("success"):
                            logging.info(f"   âœ… Deep Dive uploaded: {dd_result.get('url')}")
                        else:
                            logging.error(f"   âŒ Deep Dive upload failed: {dd_result.get('error')}")
            else:
                logging.error("âŒ YouTube authentication failed!")
                
        except Exception as e:
            logging.error(f"âŒ YouTube upload error: {e}")
            traceback.print_exc()
    
    elif ENABLE_YOUTUBE_UPLOAD and not YOUTUBE_UPLOAD_AVAILABLE:
        logging.warning("âš ï¸ YouTube upload enabled but youtube_uploader module not available.")
    
    elif not ENABLE_YOUTUBE_UPLOAD:
        logging.info("â„¹ï¸  YouTube upload disabled (set ENABLE_YOUTUBE_UPLOAD=true to enable)")

    # ------------------------------------------------------------------
    # GENERATE BLOG (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    blog_result = None
    ENABLE_BLOG = os.getenv("ENABLE_BLOG", "true").lower() == "true"
    
    if ENABLE_BLOG and BLOG_GENERATOR_AVAILABLE:
        logging.info("-" * 60)
        logging.info("ğŸ“ Generating Blog Post...")
        
        try:
            blog_result = generate_blog_from_data(json_path, "blog_output")
            if blog_result:
                logging.info(f"   âœ… Blog generated: {blog_result.get('slug')}")
        except Exception as e:
            logging.error(f"âŒ Blog generation error: {e}")
            traceback.print_exc()
    
    # ------------------------------------------------------------------
    # GENERATE PODCAST (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    podcast_result = None
    ENABLE_PODCAST = os.getenv("ENABLE_PODCAST", "true").lower() == "true"
    
    if ENABLE_PODCAST and PODCAST_GENERATOR_AVAILABLE:
        logging.info("-" * 60)
        logging.info("ğŸ™ï¸ Generating Podcast Episode...")
        
        try:
            assets_dir = os.path.join(os.path.dirname(json_path), "assets")
            # Calculate episode number from date
            episode_num = int(datetime.now().strftime("%j"))  # Day of year
            
            podcast_result = generate_podcast_from_data(
                json_path, 
                assets_dir, 
                "podcast_output",
                episode_num
            )
            if podcast_result:
                logging.info(f"   âœ… Podcast generated: {podcast_result.get('filename')} ({podcast_result.get('duration_str')})")
        except Exception as e:
            logging.error(f"âŒ Podcast generation error: {e}")
            traceback.print_exc()
    
    # ------------------------------------------------------------------
    # DEPLOY BLOG TO GITHUB PAGES (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    ENABLE_GITHUB_DEPLOY = os.getenv("ENABLE_GITHUB_DEPLOY", "false").lower() == "true"
    
    if ENABLE_GITHUB_DEPLOY and GITHUB_DEPLOYER_AVAILABLE and blog_result:
        logging.info("-" * 60)
        logging.info("ğŸš€ Deploying Blog to GitHub Pages...")
        
        try:
            deploy_success = deploy_blog_to_github("blog_output")
            if deploy_success:
                logging.info("   âœ… Blog deployed to GitHub Pages!")
            else:
                logging.error("   âŒ GitHub deployment failed")
        except Exception as e:
            logging.error(f"âŒ GitHub deploy error: {e}")
            traceback.print_exc()
    
    # ------------------------------------------------------------------
    # PUBLISH TO SOCIAL MEDIA (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    social_results = {}
    ENABLE_SOCIAL_MEDIA = os.getenv("ENABLE_SOCIAL_MEDIA", "false").lower() == "true"
    
    if ENABLE_SOCIAL_MEDIA and SOCIAL_PUBLISHER_AVAILABLE:
        logging.info("-" * 60)
        logging.info("ğŸ“± Publishing to Social Media...")
        
        try:
            social_results = publish_to_social_media(json_path)
            logging.info(f"   ğŸ“± Twitter: {'âœ…' if social_results.get('twitter') else 'âŒ'}")
            logging.info(f"   ğŸ“± Telegram: {'âœ…' if social_results.get('telegram') else 'âŒ'}")
            logging.info(f"   ğŸ“± Discord: {'âœ…' if social_results.get('discord') else 'âŒ'}")
            logging.info(f"   ğŸ“§ Email: {social_results.get('email', 0)} sent")
        except Exception as e:
            logging.error(f"âŒ Social media error: {e}")
            traceback.print_exc()

    # ------------------------------------------------------------------
    # MONETIZATION: Generate Digital Products (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    monetization_results = {}
    ENABLE_MONETIZATION = os.getenv("ENABLE_MONETIZATION", "true").lower() == "true"
    
    if ENABLE_MONETIZATION and MONETIZATION_AVAILABLE:
        logging.info("-" * 60)
        logging.info("ğŸ’° Generating Monetization Assets...")
        
        try:
            monetization_manager = MonetizationManager()
            monetization_results = monetization_manager.process_daily(final_data)
            
            if monetization_results.get("anki_deck"):
                logging.info(f"   ğŸ“š Anki Deck: {monetization_results['anki_deck']}")
            if monetization_results.get("lead_magnet"):
                logging.info(f"   ğŸ“„ Lead Magnet PDF: {monetization_results['lead_magnet']}")
            if monetization_results.get("premium_content"):
                logging.info(f"   â­ Premium Content: {monetization_results['premium_content']}")
            
            # Upload products to Drive for distribution
            if DRIVE_FOLDER_ID:
                for key in ["anki_deck", "lead_magnet", "premium_content"]:
                    file_path = monetization_results.get(key)
                    if file_path and os.path.exists(file_path):
                        upload_to_drive(file_path, DRIVE_FOLDER_ID)
                        
        except Exception as e:
            logging.error(f"âŒ Monetization error: {e}")
            traceback.print_exc()

    # ------------------------------------------------------------------
    # TELEGRAM BOT: Send Daily Push (TÃ¹y chá»n)
    # ------------------------------------------------------------------
    ENABLE_TELEGRAM_PUSH = os.getenv("ENABLE_TELEGRAM_PUSH", "false").lower() == "true"
    TELEGRAM_CHANNEL_ID = os.getenv("TELEGRAM_CHANNEL_ID", "")
    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
    
    if ENABLE_TELEGRAM_PUSH and TELEGRAM_BOT_AVAILABLE and TELEGRAM_CHANNEL_ID:
        logging.info("-" * 60)
        logging.info("ğŸ¤– Sending Telegram Daily Push...")
        
        try:
            asyncio.run(send_daily_push(TELEGRAM_BOT_TOKEN, TELEGRAM_CHANNEL_ID, json_path))
            logging.info("   âœ… Telegram push sent!")
        except Exception as e:
            logging.error(f"âŒ Telegram push error: {e}")
            traceback.print_exc()

    # --- Summary ---
    logging.info("=" * 60)
    logging.info("ğŸ HOÃ€N THÃ€NH â€” ToÃ n bá»™ pipeline Ä‘Ã£ cháº¡y xong.")
    logging.info(f"   ğŸ“„ Word: {docx_path or 'N/A'}")
    logging.info(f"   ğŸ¬ Videos rendered: {len(rendered_videos)} / 5")
    if DRIVE_FOLDER_ID:
        logging.info(f"   â˜ï¸  Drive: Uploaded to folder {DRIVE_FOLDER_ID}")
    if youtube_results:
        successful_yt = [r for r in youtube_results if r.get("success")]
        logging.info(f"   ğŸ“º YouTube: {len(successful_yt)}/{len(youtube_results)} uploaded")
        for r in successful_yt:
            logging.info(f"      â†’ {r.get('url')} ({r.get('privacy')})")
    if blog_result:
        logging.info(f"   ğŸ“ Blog: {blog_result.get('slug')}")
    if podcast_result:
        logging.info(f"   ğŸ™ï¸ Podcast: {podcast_result.get('filename')}")
    if social_results:
        logging.info(f"   ğŸ“± Social: Twitter={social_results.get('twitter')}, Telegram={social_results.get('telegram')}")
    if monetization_results:
        logging.info(f"   ğŸ’° Products: Anki={bool(monetization_results.get('anki_deck'))}, PDF={bool(monetization_results.get('lead_magnet'))}")
    if include_deep_dive:
        logging.info(f"   ğŸ“ YouTube metadata: {youtube_info_path or 'N/A'}")
    logging.info("=" * 60)


# ==============================================================================
if __name__ == "__main__":
    main()
